{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f21c38abdcb4c3fb9287dfc37849e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d57a8348c0b4f9fbf3033476ccb79a9",
              "IPY_MODEL_be579efe5b2540b898f90756b6317485",
              "IPY_MODEL_459e05de755e4d0390b3b1bf8c3a1980"
            ],
            "layout": "IPY_MODEL_648fa4f5b77942189fc0de4a5d3cdab0"
          }
        },
        "2d57a8348c0b4f9fbf3033476ccb79a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77baee453bd54a6f8df5a2ba3ae2210c",
            "placeholder": "​",
            "style": "IPY_MODEL_7e92108741a442749fe3804733699218",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "be579efe5b2540b898f90756b6317485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0eef46d79c1477bbea37f403b5c05f2",
            "max": 61,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62bf930b8b2a4fc8bb81c2db1cf68a18",
            "value": 61
          }
        },
        "459e05de755e4d0390b3b1bf8c3a1980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65069c5c10c64321b6ae9ffa7fddb7a2",
            "placeholder": "​",
            "style": "IPY_MODEL_f83a755d8bc942d39ce88d1f8f2e611b",
            "value": " 61.0/61.0 [00:00&lt;00:00, 4.93kB/s]"
          }
        },
        "648fa4f5b77942189fc0de4a5d3cdab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77baee453bd54a6f8df5a2ba3ae2210c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e92108741a442749fe3804733699218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0eef46d79c1477bbea37f403b5c05f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62bf930b8b2a4fc8bb81c2db1cf68a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65069c5c10c64321b6ae9ffa7fddb7a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83a755d8bc942d39ce88d1f8f2e611b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4851b43836c7457da4cfaea19a393bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_304c9225b3a74089bceab5e3bacc1525",
              "IPY_MODEL_bbcd332037cd42f2acc2d10408c222f5",
              "IPY_MODEL_8e210212fdb84408898a07a82c0174b8"
            ],
            "layout": "IPY_MODEL_3dd0882b8fc24734863c5ed948e9bf84"
          }
        },
        "304c9225b3a74089bceab5e3bacc1525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99f502761aeb4e428db564b182aca7f0",
            "placeholder": "​",
            "style": "IPY_MODEL_c324bceb7cbf44e1b903bd8c3840f761",
            "value": "vocab.txt: 100%"
          }
        },
        "bbcd332037cd42f2acc2d10408c222f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e5b7c136dd04521ab89e28cdebc7327",
            "max": 263326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f516712b1be540aab80d9cc14a883989",
            "value": 263326
          }
        },
        "8e210212fdb84408898a07a82c0174b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11dd14703ff7491f96de49291837efe3",
            "placeholder": "​",
            "style": "IPY_MODEL_b03afb135ca24c8da6e0b52fab60081f",
            "value": " 263k/263k [00:00&lt;00:00, 5.36MB/s]"
          }
        },
        "3dd0882b8fc24734863c5ed948e9bf84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99f502761aeb4e428db564b182aca7f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c324bceb7cbf44e1b903bd8c3840f761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e5b7c136dd04521ab89e28cdebc7327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f516712b1be540aab80d9cc14a883989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11dd14703ff7491f96de49291837efe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03afb135ca24c8da6e0b52fab60081f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e6fd0084d304d67be49f6f7776343a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be8a47f0aa224603bb4dd787d017025f",
              "IPY_MODEL_25a46b08a9d24a6aad03d569c22254e5",
              "IPY_MODEL_82d9d2be19d54a559bf771ea445e596f"
            ],
            "layout": "IPY_MODEL_601acfb81aa34992bf0c4cbd02104748"
          }
        },
        "be8a47f0aa224603bb4dd787d017025f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a3f06551763458a98d36e62f32c7d2c",
            "placeholder": "​",
            "style": "IPY_MODEL_440a606661ed4fd5bfb0eae0a9b73747",
            "value": "config.json: 100%"
          }
        },
        "25a46b08a9d24a6aad03d569c22254e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eb279f6deb64fe3a427da7c2e6a8ac1",
            "max": 467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6fececd07644ce4907b9dd53dd45774",
            "value": 467
          }
        },
        "82d9d2be19d54a559bf771ea445e596f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb44fe7691894b3d88e5262e2becbb7e",
            "placeholder": "​",
            "style": "IPY_MODEL_ae3222e2090b4211867c704932c8d509",
            "value": " 467/467 [00:00&lt;00:00, 40.9kB/s]"
          }
        },
        "601acfb81aa34992bf0c4cbd02104748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a3f06551763458a98d36e62f32c7d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440a606661ed4fd5bfb0eae0a9b73747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1eb279f6deb64fe3a427da7c2e6a8ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6fececd07644ce4907b9dd53dd45774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb44fe7691894b3d88e5262e2becbb7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae3222e2090b4211867c704932c8d509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3882038a3a2a49479696c3f3be1be2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6860da6727641f2a62d4bcc8646887b",
              "IPY_MODEL_6a78ad8937934f6ab22e3899c3fad89e",
              "IPY_MODEL_c512eb8cecfb4f9a8e7322959eaba4be"
            ],
            "layout": "IPY_MODEL_60d03cd1c25948b18c0dc93378396931"
          }
        },
        "d6860da6727641f2a62d4bcc8646887b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec173feed38a494297063f4be9e05a9f",
            "placeholder": "​",
            "style": "IPY_MODEL_aa10eaf11a3847eb98a65bc3ec91c32d",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "6a78ad8937934f6ab22e3899c3fad89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec0d95917f3842dea67e36e335345391",
            "max": 451741507,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95d73173009949b6bf88e0d8add6c866",
            "value": 451741507
          }
        },
        "c512eb8cecfb4f9a8e7322959eaba4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea9f6986cd174324b411df635c73b0e3",
            "placeholder": "​",
            "style": "IPY_MODEL_293d0565fbf740b1bd6d16da6ca338de",
            "value": " 452M/452M [00:01&lt;00:00, 271MB/s]"
          }
        },
        "60d03cd1c25948b18c0dc93378396931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec173feed38a494297063f4be9e05a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa10eaf11a3847eb98a65bc3ec91c32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec0d95917f3842dea67e36e335345391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d73173009949b6bf88e0d8add6c866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea9f6986cd174324b411df635c73b0e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293d0565fbf740b1bd6d16da6ca338de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3ee5be0f3a443e8a56f0b45423b8e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e9ad70df96a41bc89cc1f836b719c8d",
              "IPY_MODEL_e7ce43b208ae4c989bf9ab965a632ec1",
              "IPY_MODEL_1616e4abe83f4a0e9dc06952bd75186a"
            ],
            "layout": "IPY_MODEL_7e7f195af072462cb18e9740f06ecef6"
          }
        },
        "3e9ad70df96a41bc89cc1f836b719c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab671af8b4b544e99a72159e8856fa6c",
            "placeholder": "​",
            "style": "IPY_MODEL_6a1694ed7254464e83c312aeb43049d8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e7ce43b208ae4c989bf9ab965a632ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_204ea7853d164cb98c361e5360c7d087",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_127bb70d41da497781035103822141fd",
            "value": 49
          }
        },
        "1616e4abe83f4a0e9dc06952bd75186a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af383932dc13436287802fa5e1ac9474",
            "placeholder": "​",
            "style": "IPY_MODEL_46dd0446cf8748bdb3b87542f7fc8d6d",
            "value": " 49.0/49.0 [00:00&lt;00:00, 3.96kB/s]"
          }
        },
        "7e7f195af072462cb18e9740f06ecef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab671af8b4b544e99a72159e8856fa6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a1694ed7254464e83c312aeb43049d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "204ea7853d164cb98c361e5360c7d087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127bb70d41da497781035103822141fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af383932dc13436287802fa5e1ac9474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46dd0446cf8748bdb3b87542f7fc8d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcade4d63bb546148478600239094772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_895a62b06af24fa987077ea5281607a7",
              "IPY_MODEL_bf8190644cf24f0c9d488f6eee6f8cbe",
              "IPY_MODEL_7445716486824700863ccb7abad9e8f9"
            ],
            "layout": "IPY_MODEL_27047da3b94c45f089e71e45f8ef25c3"
          }
        },
        "895a62b06af24fa987077ea5281607a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55ff26cb86d4415b90a9670fdbb3cecd",
            "placeholder": "​",
            "style": "IPY_MODEL_6f88c25a6d4f4749916ea7673c23c780",
            "value": "vocab.txt: 100%"
          }
        },
        "bf8190644cf24f0c9d488f6eee6f8cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec2aaede99ab4a5ca510bffd53742a30",
            "max": 249928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c28f73e269b7497aba26ab1b6637b2a5",
            "value": 249928
          }
        },
        "7445716486824700863ccb7abad9e8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6671324188b4380a4bffd9e85d8108a",
            "placeholder": "​",
            "style": "IPY_MODEL_18fb4ab0228a4e14b1a696e726e77e3e",
            "value": " 250k/250k [00:00&lt;00:00, 5.50MB/s]"
          }
        },
        "27047da3b94c45f089e71e45f8ef25c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ff26cb86d4415b90a9670fdbb3cecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f88c25a6d4f4749916ea7673c23c780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec2aaede99ab4a5ca510bffd53742a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c28f73e269b7497aba26ab1b6637b2a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6671324188b4380a4bffd9e85d8108a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18fb4ab0228a4e14b1a696e726e77e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48a4774195c4412dbe800186ee969be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8b25e08c434442793712525e0432c4a",
              "IPY_MODEL_f219563df232449598d57cbe05dea469",
              "IPY_MODEL_4ba7d33f3e5340639922b8f6b862457a"
            ],
            "layout": "IPY_MODEL_06fc2cd7d34e4448bb3cea46c9589be9"
          }
        },
        "a8b25e08c434442793712525e0432c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_185ae509bb874938ad9465d47e8dcad1",
            "placeholder": "​",
            "style": "IPY_MODEL_cf537a0d58ea424abd1fa2a02cea84d7",
            "value": "config.json: 100%"
          }
        },
        "f219563df232449598d57cbe05dea469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97dcb3e575a44b7abc3c177f0ec027d1",
            "max": 619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c52b3d1049648a68e00bd7907116f35",
            "value": 619
          }
        },
        "4ba7d33f3e5340639922b8f6b862457a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c9228e3519b438c95dc82951cafd9f7",
            "placeholder": "​",
            "style": "IPY_MODEL_33f34f6e4f1941fd94718813dfba0093",
            "value": " 619/619 [00:00&lt;00:00, 53.6kB/s]"
          }
        },
        "06fc2cd7d34e4448bb3cea46c9589be9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185ae509bb874938ad9465d47e8dcad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf537a0d58ea424abd1fa2a02cea84d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97dcb3e575a44b7abc3c177f0ec027d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c52b3d1049648a68e00bd7907116f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c9228e3519b438c95dc82951cafd9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33f34f6e4f1941fd94718813dfba0093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "044ed50696bd4b29820114354aa76a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3adafcfd1a94dc29b256f67aac90a6d",
              "IPY_MODEL_307807e8871747f3bc508a6246c5d520",
              "IPY_MODEL_83c63f76458c48df864541bb306c8ccc"
            ],
            "layout": "IPY_MODEL_8e98383dcb444a16beb2ce0e3fb751b7"
          }
        },
        "c3adafcfd1a94dc29b256f67aac90a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab3bc024d744cc4b1ec3ceddd161f3e",
            "placeholder": "​",
            "style": "IPY_MODEL_155c0e91115c4abf8fa3c5aea844cc52",
            "value": "model.safetensors: 100%"
          }
        },
        "307807e8871747f3bc508a6246c5d520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e320b1075e94673aac2d9bb12a0a399",
            "max": 438192852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7799f23208e149e78e45e3d306907861",
            "value": 438192852
          }
        },
        "83c63f76458c48df864541bb306c8ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8421206c15754ed184254466db635ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_ae5928448d6244c8af5083b01c879e0b",
            "value": " 438M/438M [00:02&lt;00:00, 248MB/s]"
          }
        },
        "8e98383dcb444a16beb2ce0e3fb751b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab3bc024d744cc4b1ec3ceddd161f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "155c0e91115c4abf8fa3c5aea844cc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e320b1075e94673aac2d9bb12a0a399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7799f23208e149e78e45e3d306907861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8421206c15754ed184254466db635ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae5928448d6244c8af5083b01c879e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiCda-Xe14Z9",
        "outputId": "66074cf5-2a47-47aa-af05-2e7eafbddd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **klue/bert-base 모델**"
      ],
      "metadata": {
        "id": "SAASXZ6W2eMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# GPU 사용 설정 (CUDA가 사용 가능한 경우)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"GPU available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwI6Y1ayJvv9",
        "outputId": "6ff73de3-0dd2-4b16-e521-ea17aeb33c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 클래스 정의\n",
        "class LegalDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = eval(self.data.iloc[idx]['tokens_klue'])  # 토큰화된 데이터를 리스트로 변환\n",
        "        tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "        label = torch.tensor(self.data.iloc[idx]['label'], dtype=torch.long)\n",
        "        return tokens, label\n",
        "\n",
        "def collate_fn(batch):\n",
        "    tokens, labels = zip(*batch)\n",
        "\n",
        "    # 각 샘플의 tokens 길이가 다를 수 있으므로 패딩 적용\n",
        "    tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    # Attention mask 추가 (패딩된 토큰을 0으로, 나머지를 1로 설정)\n",
        "    attention_mask = (tokens_padded != tokenizer.pad_token_id).long()\n",
        "\n",
        "    labels = torch.tensor(labels)\n",
        "    return tokens_padded, attention_mask, labels"
      ],
      "metadata": {
        "id": "4K4U5p7iKJfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 토크나이저 불러오기\n",
        "model_name = 'klue/bert-base'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=13)\n",
        "model.to(device)\n",
        "\n",
        "# 미리 토큰화된 데이터 불러오기\n",
        "df = pd.read_csv('/content/drive/MyDrive/df_klue.csv')\n",
        "\n",
        "# 빈 리스트([])가 있는 행 제거\n",
        "df = df[df['tokens_klue'].apply(lambda x: len(eval(x)) > 0)]\n",
        "\n",
        "# '판결유형' 컬럼을 라벨로 변환\n",
        "label_map = {'민사_승소': 0, '민사_패소': 1, '민사_기각': 2, '징역': 3, '무혐의': 4, '벌금': 5, '형사_기각': 6, '가사_승소': 7, '가사_패소': 8, '가사_기각': 9, '세무_승소': 10, '세무_패소': 11, '세무_기각': 12}\n",
        "df['label'] = df['판결유형'].map(label_map)\n",
        "\n",
        "print(\"데이터 불러오기 및 라벨 변환 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiXk9p1LKJal",
        "outputId": "9f5b940a-d71a-4895-d343-a1dc3181c884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 불러오기 및 라벨 변환 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-76911ac4cc47>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = df['판결유형'].map(label_map)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사건종류와 판결유형을 7:3으로 분리, 'label'만을 기준으로 stratify\n",
        "train_data, valid_data = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
        "\n",
        "# 클래스별 데이터 수를 계산하여 가중치 설정\n",
        "class_weights = compute_class_weight('balanced', classes=df['label'].unique(), y=train_data['label'])\n",
        "weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "print(\"데이터 분리 및 가중치 설정 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4_WGi9XKJWP",
        "outputId": "29a7f36c-812e-48c3-8089-ab4c892e846c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 분리 및 가중치 설정 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터셋과 데이터로더 정의\n",
        "train_dataset = LegalDataset(train_data)\n",
        "valid_dataset = LegalDataset(valid_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Optimizer 설정\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# CrossEntropyLoss에 가중치 적용\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "print(\"데이터로더 및 Optimizer 설정 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-TfZo_pKJLS",
        "outputId": "b6430048-08f4-4a44-ae74-cbd1404d2e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터로더 및 Optimizer 설정 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# 성능 지표 계산 함수 추가\n",
        "def calculate_metrics(predictions, labels):\n",
        "    preds = predictions.argmax(dim=1).cpu().numpy()  # 예측 결과\n",
        "    labels = labels.cpu().numpy()  # 실제 라벨\n",
        "\n",
        "    precision = precision_score(labels, preds, average='weighted', zero_division=1)\n",
        "    recall = recall_score(labels, preds, average='weighted', zero_division=1)\n",
        "    f1 = f1_score(labels, preds, average='weighted', zero_division=1)\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "# 학습 함수에서 precision, recall, f1 추가\n",
        "def train(model, loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    total_batches = len(loader)\n",
        "    progress_bar = tqdm(total=total_batches, desc=f\"Training Epoch {epoch}\", unit='batch', dynamic_ncols=True, mininterval=1)\n",
        "\n",
        "    for batch_idx, (tokens, attention_mask, labels) in enumerate(loader):\n",
        "        tokens, attention_mask, labels = tokens.to(device), attention_mask.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=tokens, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += (outputs.logits.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "        all_preds.append(outputs.logits)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "        # 25%마다 진행 상황 업데이트\n",
        "        if (batch_idx + 1) % (total_batches // 4) == 0:\n",
        "            progress_bar.update(total_batches // 4)\n",
        "            progress_bar.set_postfix(loss=total_loss / (batch_idx + 1), accuracy=total_correct / ((batch_idx + 1) * loader.batch_size))\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    # Precision, Recall, F1 계산\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    precision, recall, f1 = calculate_metrics(all_preds, all_labels)\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    accuracy = total_correct / len(loader.dataset)\n",
        "    return avg_loss, accuracy, precision, recall, f1\n",
        "\n",
        "# 검증 함수에서 precision, recall, f1 추가\n",
        "def validate(model, loader, epoch):\n",
        "    model.eval()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    total_batches = len(loader)\n",
        "    progress_bar = tqdm(total=total_batches, desc=f\"Validation Epoch {epoch}\", unit='batch', dynamic_ncols=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (tokens, attention_mask, labels) in enumerate(loader):\n",
        "            tokens, attention_mask, labels = tokens.to(device), attention_mask.to(device), labels.to(device)\n",
        "            outputs = model(input_ids=tokens, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += (outputs.logits.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "            all_preds.append(outputs.logits)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "            # 50%마다 진행 상황 업데이트\n",
        "            if (batch_idx + 1) % (total_batches // 2) == 0:\n",
        "                progress_bar.update(total_batches // 2)\n",
        "                progress_bar.set_postfix(loss=total_loss / (batch_idx + 1), accuracy=total_correct / ((batch_idx + 1) * loader.batch_size))\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    # Precision, Recall, F1 계산\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    precision, recall, f1 = calculate_metrics(all_preds, all_labels)\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    accuracy = total_correct / len(loader.dataset)\n",
        "    return avg_loss, accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "lXl3x07lK_lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기 변수 설정\n",
        "best_val_loss = float('inf')  # 가장 좋은 검증 손실을 초기화\n",
        "\n",
        "# 학습 및 검증 함수 실행\n",
        "train_accuracies, val_accuracies = [], []\n",
        "train_losses, val_losses = [], []\n",
        "precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "for epoch in range(20):\n",
        "    train_loss, train_acc, train_precision, train_recall, train_f1 = train(model, train_loader, optimizer, epoch)\n",
        "    val_loss, val_acc, val_precision, val_recall, val_f1 = validate(model, valid_loader, epoch)\n",
        "\n",
        "    # 각 모델의 결과 저장\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "    precisions.append(val_precision)\n",
        "    recalls.append(val_recall)\n",
        "    f1_scores.append(val_f1)\n",
        "\n",
        "    # 조기 종료 및 모델 저장\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        # 폴더가 없으면 생성\n",
        "        if not os.path.exists(model_name):\n",
        "            os.makedirs(model_name)\n",
        "        # 모델 저장\n",
        "        torch.save(model.state_dict(), f'{model_name}/best_model.pth')\n",
        "\n",
        "print(\"학습 및 검증 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LNdFzo0K_g8",
        "outputId": "f8591db4-2e54-4085-f52a-caf3bf43bac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training Epoch 0:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 0:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s]\u001b[A\n",
            "Training Epoch 0:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s, accuracy=0.866, loss=0.498]\u001b[A\n",
            "Training Epoch 0:  25%|██▍       | 922/3689 [02:49<07:50,  5.89batch/s, accuracy=0.866, loss=0.498]\u001b[A\n",
            "Training Epoch 0:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.866, loss=0.498]\u001b[A\n",
            "Training Epoch 0:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.905, loss=0.353]\u001b[A\n",
            "Training Epoch 0:  50%|████▉     | 1844/3689 [05:25<05:13,  5.89batch/s, accuracy=0.905, loss=0.353]\u001b[A\n",
            "Training Epoch 0:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.905, loss=0.353]\u001b[A\n",
            "Training Epoch 0:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.918, loss=0.295]\u001b[A\n",
            "Training Epoch 0:  75%|███████▍  | 2766/3689 [07:59<02:36,  5.90batch/s, accuracy=0.918, loss=0.295]\u001b[A\n",
            "Training Epoch 0: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.918, loss=0.295]\u001b[A\n",
            "Training Epoch 0: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.89batch/s, accuracy=0.926, loss=0.261]\n",
            "\n",
            "Validation Epoch 0:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 0:  50%|████▉     | 790/1581 [00:45<00:46, 17.17batch/s]\u001b[A\n",
            "Validation Epoch 0:  50%|████▉     | 790/1581 [00:46<00:46, 17.17batch/s, accuracy=0.957, loss=0.142]\u001b[A\n",
            "Validation Epoch 0:  50%|████▉     | 790/1581 [00:59<00:46, 17.17batch/s, accuracy=0.957, loss=0.142]\u001b[A\n",
            "Validation Epoch 0: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.13batch/s, accuracy=0.957, loss=0.142]\u001b[A\n",
            "Validation Epoch 0: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.12batch/s, accuracy=0.955, loss=0.145]\n",
            "\n",
            "Training Epoch 1:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 1:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s]\u001b[A\n",
            "Training Epoch 1:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s, accuracy=0.961, loss=0.126]\u001b[A\n",
            "Training Epoch 1:  25%|██▍       | 922/3689 [02:49<07:50,  5.89batch/s, accuracy=0.961, loss=0.126]\u001b[A\n",
            "Training Epoch 1:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.961, loss=0.126]\u001b[A\n",
            "Training Epoch 1:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.962, loss=0.123]\u001b[A\n",
            "Training Epoch 1:  50%|████▉     | 1844/3689 [05:26<05:12,  5.90batch/s, accuracy=0.962, loss=0.123]\u001b[A\n",
            "Training Epoch 1:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.962, loss=0.123]\u001b[A\n",
            "Training Epoch 1:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.963, loss=0.122]\u001b[A\n",
            "Training Epoch 1:  75%|███████▍  | 2766/3689 [07:59<02:36,  5.90batch/s, accuracy=0.963, loss=0.122]\u001b[A\n",
            "Training Epoch 1: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.963, loss=0.122]\u001b[A\n",
            "Training Epoch 1: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.963, loss=0.118]\n",
            "\n",
            "Validation Epoch 1:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 1:  50%|████▉     | 790/1581 [00:46<00:46, 17.16batch/s]\u001b[A\n",
            "Validation Epoch 1:  50%|████▉     | 790/1581 [00:46<00:46, 17.16batch/s, accuracy=0.966, loss=0.115]\u001b[A\n",
            "Validation Epoch 1:  50%|████▉     | 790/1581 [00:59<00:46, 17.16batch/s, accuracy=0.966, loss=0.115]\u001b[A\n",
            "Validation Epoch 1: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.16batch/s, accuracy=0.966, loss=0.115]\u001b[A\n",
            "Validation Epoch 1: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.15batch/s, accuracy=0.965, loss=0.115]\n",
            "\n",
            "Training Epoch 2:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 2:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s]\u001b[A\n",
            "Training Epoch 2:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s, accuracy=0.971, loss=0.0924]\u001b[A\n",
            "Training Epoch 2:  25%|██▍       | 922/3689 [02:49<07:49,  5.89batch/s, accuracy=0.971, loss=0.0924]\u001b[A\n",
            "Training Epoch 2:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.971, loss=0.0924]\u001b[A\n",
            "Training Epoch 2:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.969, loss=0.0944]\u001b[A\n",
            "Training Epoch 2:  50%|████▉     | 1844/3689 [05:26<05:13,  5.89batch/s, accuracy=0.969, loss=0.0944]\u001b[A\n",
            "Training Epoch 2:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.969, loss=0.0944]\u001b[A\n",
            "Training Epoch 2:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.97, loss=0.0922] \u001b[A\n",
            "Training Epoch 2:  75%|███████▍  | 2766/3689 [08:00<02:36,  5.90batch/s, accuracy=0.97, loss=0.0922]\u001b[A\n",
            "Training Epoch 2: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.97, loss=0.0922]\u001b[A\n",
            "Training Epoch 2: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.97, loss=0.0941]\n",
            "\n",
            "Validation Epoch 2:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 2:  50%|████▉     | 790/1581 [00:46<00:46, 17.14batch/s]\u001b[A\n",
            "Validation Epoch 2:  50%|████▉     | 790/1581 [00:46<00:46, 17.14batch/s, accuracy=0.965, loss=0.112]\u001b[A\n",
            "Validation Epoch 2:  50%|████▉     | 790/1581 [00:59<00:46, 17.14batch/s, accuracy=0.965, loss=0.112]\u001b[A\n",
            "Validation Epoch 2: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.14batch/s, accuracy=0.965, loss=0.112]\u001b[A\n",
            "Validation Epoch 2: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.13batch/s, accuracy=0.966, loss=0.111]\n",
            "\n",
            "Training Epoch 3:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 3:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s]\u001b[A\n",
            "Training Epoch 3:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s, accuracy=0.974, loss=0.0809]\u001b[A\n",
            "Training Epoch 3:  25%|██▍       | 922/3689 [02:49<07:49,  5.89batch/s, accuracy=0.974, loss=0.0809]\u001b[A\n",
            "Training Epoch 3:  50%|████▉     | 1844/3689 [05:12<05:12,  5.89batch/s, accuracy=0.974, loss=0.0809]\u001b[A\n",
            "Training Epoch 3:  50%|████▉     | 1844/3689 [05:12<05:12,  5.89batch/s, accuracy=0.976, loss=0.0775]\u001b[A\n",
            "Training Epoch 3:  50%|████▉     | 1844/3689 [05:26<05:12,  5.89batch/s, accuracy=0.976, loss=0.0775]\u001b[A\n",
            "Training Epoch 3:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.976, loss=0.0775]\u001b[A\n",
            "Training Epoch 3:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.976, loss=0.0772]\u001b[A\n",
            "Training Epoch 3:  75%|███████▍  | 2766/3689 [08:00<02:36,  5.90batch/s, accuracy=0.976, loss=0.0772]\u001b[A\n",
            "Training Epoch 3: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.976, loss=0.0772]\u001b[A\n",
            "Training Epoch 3: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.975, loss=0.0775]\n",
            "\n",
            "Validation Epoch 3:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 3:  50%|████▉     | 790/1581 [00:45<00:46, 17.18batch/s]\u001b[A\n",
            "Validation Epoch 3:  50%|████▉     | 790/1581 [00:45<00:46, 17.18batch/s, accuracy=0.966, loss=0.112]\u001b[A\n",
            "Validation Epoch 3:  50%|████▉     | 790/1581 [00:59<00:46, 17.18batch/s, accuracy=0.966, loss=0.112]\u001b[A\n",
            "Validation Epoch 3: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.17batch/s, accuracy=0.966, loss=0.112]\u001b[A\n",
            "Validation Epoch 3: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.16batch/s, accuracy=0.967, loss=0.11]\n",
            "\n",
            "Training Epoch 4:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 4:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s]\u001b[A\n",
            "Training Epoch 4:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s, accuracy=0.981, loss=0.0572]\u001b[A\n",
            "Training Epoch 4:  25%|██▍       | 922/3689 [02:46<07:50,  5.89batch/s, accuracy=0.981, loss=0.0572]\u001b[A\n",
            "Training Epoch 4:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.981, loss=0.0572]\u001b[A\n",
            "Training Epoch 4:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.982, loss=0.0554]\u001b[A\n",
            "Training Epoch 4:  50%|████▉     | 1844/3689 [05:26<05:12,  5.90batch/s, accuracy=0.982, loss=0.0554]\u001b[A\n",
            "Training Epoch 4:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.982, loss=0.0554]\u001b[A\n",
            "Training Epoch 4:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.98, loss=0.062]  \u001b[A\n",
            "Training Epoch 4:  75%|███████▍  | 2766/3689 [08:00<02:36,  5.90batch/s, accuracy=0.98, loss=0.062]\u001b[A\n",
            "Training Epoch 4: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.98, loss=0.062]\u001b[A\n",
            "Training Epoch 4: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.979, loss=0.0653]\n",
            "\n",
            "Validation Epoch 4:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 4:  50%|████▉     | 790/1581 [00:46<00:46, 17.15batch/s]\u001b[A\n",
            "Validation Epoch 4:  50%|████▉     | 790/1581 [00:46<00:46, 17.15batch/s, accuracy=0.97, loss=0.109]\u001b[A\n",
            "Validation Epoch 4:  50%|████▉     | 790/1581 [01:00<00:46, 17.15batch/s, accuracy=0.97, loss=0.109]\u001b[A\n",
            "Validation Epoch 4: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.09batch/s, accuracy=0.97, loss=0.109]\u001b[A\n",
            "Validation Epoch 4: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.08batch/s, accuracy=0.97, loss=0.111]\n",
            "\n",
            "Training Epoch 5:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 5:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s]\u001b[A\n",
            "Training Epoch 5:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s, accuracy=0.985, loss=0.05]\u001b[A\n",
            "Training Epoch 5:  25%|██▍       | 922/3689 [02:48<07:49,  5.89batch/s, accuracy=0.985, loss=0.05]\u001b[A\n",
            "Training Epoch 5:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.985, loss=0.05]\u001b[A\n",
            "Training Epoch 5:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.985, loss=0.0501]\u001b[A\n",
            "Training Epoch 5:  50%|████▉     | 1844/3689 [05:28<05:13,  5.89batch/s, accuracy=0.985, loss=0.0501]\u001b[A\n",
            "Training Epoch 5:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.985, loss=0.0501]\u001b[A\n",
            "Training Epoch 5:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.984, loss=0.0518]\u001b[A\n",
            "Training Epoch 5:  75%|███████▍  | 2766/3689 [08:01<02:36,  5.90batch/s, accuracy=0.984, loss=0.0518]\u001b[A\n",
            "Training Epoch 5: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.984, loss=0.0518]\u001b[A\n",
            "Training Epoch 5: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.984, loss=0.052]\n",
            "\n",
            "Validation Epoch 5:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 5:  50%|████▉     | 790/1581 [00:46<00:46, 17.04batch/s]\u001b[A\n",
            "Validation Epoch 5:  50%|████▉     | 790/1581 [00:46<00:46, 17.04batch/s, accuracy=0.966, loss=0.126]\u001b[A\n",
            "Validation Epoch 5:  50%|████▉     | 790/1581 [01:01<00:46, 17.04batch/s, accuracy=0.966, loss=0.126]\u001b[A\n",
            "Validation Epoch 5: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.07batch/s, accuracy=0.966, loss=0.126]\u001b[A\n",
            "Validation Epoch 5: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.05batch/s, accuracy=0.969, loss=0.125]\n",
            "\n",
            "Training Epoch 6:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 6:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s]\u001b[A\n",
            "Training Epoch 6:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s, accuracy=0.987, loss=0.0412]\u001b[A\n",
            "Training Epoch 6:  25%|██▍       | 922/3689 [02:48<07:49,  5.89batch/s, accuracy=0.987, loss=0.0412]\u001b[A\n",
            "Training Epoch 6:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.987, loss=0.0412]\u001b[A\n",
            "Training Epoch 6:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.986, loss=0.0437]\u001b[A\n",
            "Training Epoch 6:  50%|████▉     | 1844/3689 [05:28<05:12,  5.90batch/s, accuracy=0.986, loss=0.0437]\u001b[A\n",
            "Training Epoch 6:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.986, loss=0.0437]\u001b[A\n",
            "Training Epoch 6:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.986, loss=0.0445]\u001b[A\n",
            "Training Epoch 6:  75%|███████▍  | 2766/3689 [07:58<02:36,  5.90batch/s, accuracy=0.986, loss=0.0445]\u001b[A\n",
            "Training Epoch 6: 100%|█████████▉| 3688/3689 [10:24<00:00,  5.90batch/s, accuracy=0.986, loss=0.0445]\u001b[A\n",
            "Training Epoch 6: 100%|█████████▉| 3688/3689 [10:24<00:00,  5.90batch/s, accuracy=0.986, loss=0.0445]\n",
            "\n",
            "Validation Epoch 6:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 6:  50%|████▉     | 790/1581 [00:46<00:46, 17.14batch/s]\u001b[A\n",
            "Validation Epoch 6:  50%|████▉     | 790/1581 [00:46<00:46, 17.14batch/s, accuracy=0.961, loss=0.144]\u001b[A\n",
            "Validation Epoch 6:  50%|████▉     | 790/1581 [00:56<00:46, 17.14batch/s, accuracy=0.961, loss=0.144]\u001b[A\n",
            "Validation Epoch 6: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.15batch/s, accuracy=0.961, loss=0.144]\u001b[A\n",
            "Validation Epoch 6: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.13batch/s, accuracy=0.962, loss=0.141]\n",
            "\n",
            "Training Epoch 7:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 7:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s]\u001b[A\n",
            "Training Epoch 7:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s, accuracy=0.993, loss=0.0251]\u001b[A\n",
            "Training Epoch 7:  25%|██▍       | 922/3689 [02:50<07:49,  5.89batch/s, accuracy=0.993, loss=0.0251]\u001b[A\n",
            "Training Epoch 7:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.993, loss=0.0251]\u001b[A\n",
            "Training Epoch 7:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.991, loss=0.0325]\u001b[A\n",
            "Training Epoch 7:  50%|████▉     | 1844/3689 [05:24<05:12,  5.90batch/s, accuracy=0.991, loss=0.0325]\u001b[A\n",
            "Training Epoch 7:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.991, loss=0.0325]\u001b[A\n",
            "Training Epoch 7:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.99, loss=0.0342] \u001b[A\n",
            "Training Epoch 7:  75%|███████▍  | 2766/3689 [08:00<02:36,  5.90batch/s, accuracy=0.99, loss=0.0342]\u001b[A\n",
            "Training Epoch 7: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.99, loss=0.0342]\u001b[A\n",
            "Training Epoch 7: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.99, loss=0.0346]\n",
            "\n",
            "Validation Epoch 7:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 7:  50%|████▉     | 790/1581 [00:46<00:46, 17.15batch/s]\u001b[A\n",
            "Validation Epoch 7:  50%|████▉     | 790/1581 [00:46<00:46, 17.15batch/s, accuracy=0.962, loss=0.141]\u001b[A\n",
            "Validation Epoch 7:  50%|████▉     | 790/1581 [00:57<00:46, 17.15batch/s, accuracy=0.962, loss=0.141]\u001b[A\n",
            "Validation Epoch 7: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.14batch/s, accuracy=0.962, loss=0.141]\u001b[A\n",
            "Validation Epoch 7: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.13batch/s, accuracy=0.963, loss=0.138]\n",
            "\n",
            "Training Epoch 8:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 8:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s]\u001b[A\n",
            "Training Epoch 8:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s, accuracy=0.992, loss=0.0248]\u001b[A\n",
            "Training Epoch 8:  25%|██▍       | 922/3689 [02:51<07:49,  5.89batch/s, accuracy=0.992, loss=0.0248]\u001b[A\n",
            "Training Epoch 8:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.992, loss=0.0248]\u001b[A\n",
            "Training Epoch 8:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.992, loss=0.0268]\u001b[A\n",
            "Training Epoch 8:  50%|████▉     | 1844/3689 [05:25<05:12,  5.90batch/s, accuracy=0.992, loss=0.0268]\u001b[A\n",
            "Training Epoch 8:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.992, loss=0.0268]\u001b[A\n",
            "Training Epoch 8:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.992, loss=0.0276]\u001b[A\n",
            "Training Epoch 8:  75%|███████▍  | 2766/3689 [08:01<02:36,  5.90batch/s, accuracy=0.992, loss=0.0276]\u001b[A\n",
            "Training Epoch 8: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.992, loss=0.0276]\u001b[A\n",
            "Training Epoch 8: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.991, loss=0.0302]\n",
            "\n",
            "Validation Epoch 8:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 8:  50%|████▉     | 790/1581 [00:46<00:46, 17.14batch/s]\u001b[A\n",
            "Validation Epoch 8:  50%|████▉     | 790/1581 [00:46<00:46, 17.14batch/s, accuracy=0.962, loss=0.159]\u001b[A\n",
            "Validation Epoch 8:  50%|████▉     | 790/1581 [00:58<00:46, 17.14batch/s, accuracy=0.962, loss=0.159]\u001b[A\n",
            "Validation Epoch 8: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.14batch/s, accuracy=0.962, loss=0.159]\u001b[A\n",
            "Validation Epoch 8: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.13batch/s, accuracy=0.964, loss=0.155]\n",
            "\n",
            "Training Epoch 9:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 9:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s]\u001b[A\n",
            "Training Epoch 9:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s, accuracy=0.993, loss=0.0219]\u001b[A\n",
            "Training Epoch 9:  25%|██▍       | 922/3689 [02:46<07:49,  5.89batch/s, accuracy=0.993, loss=0.0219]\u001b[A\n",
            "Training Epoch 9:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.993, loss=0.0219]\u001b[A\n",
            "Training Epoch 9:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.992, loss=0.0244]\u001b[A\n",
            "Training Epoch 9:  50%|████▉     | 1844/3689 [05:23<05:12,  5.90batch/s, accuracy=0.992, loss=0.0244]\u001b[A\n",
            "Training Epoch 9:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.992, loss=0.0244]\u001b[A\n",
            "Training Epoch 9:  75%|███████▍  | 2766/3689 [07:48<02:36,  5.90batch/s, accuracy=0.992, loss=0.0263]\u001b[A\n",
            "Training Epoch 9:  75%|███████▍  | 2766/3689 [08:03<02:36,  5.90batch/s, accuracy=0.992, loss=0.0263]\u001b[A\n",
            "Training Epoch 9: 100%|█████████▉| 3688/3689 [10:24<00:00,  5.90batch/s, accuracy=0.992, loss=0.0263]\u001b[A\n",
            "Training Epoch 9: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.992, loss=0.0255]\n",
            "\n",
            "Validation Epoch 9:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 9:  50%|████▉     | 790/1581 [00:46<00:46, 17.00batch/s]\u001b[A\n",
            "Validation Epoch 9:  50%|████▉     | 790/1581 [00:46<00:46, 17.00batch/s, accuracy=0.965, loss=0.159]\u001b[A\n",
            "Validation Epoch 9:  50%|████▉     | 790/1581 [00:56<00:46, 17.00batch/s, accuracy=0.965, loss=0.159]\u001b[A\n",
            "Validation Epoch 9: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.05batch/s, accuracy=0.965, loss=0.159]\u001b[A\n",
            "Validation Epoch 9: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.03batch/s, accuracy=0.966, loss=0.157]\n",
            "\n",
            "Training Epoch 10:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 10:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s]\u001b[A\n",
            "Training Epoch 10:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s, accuracy=0.996, loss=0.0129]\u001b[A\n",
            "Training Epoch 10:  25%|██▍       | 922/3689 [02:47<07:50,  5.89batch/s, accuracy=0.996, loss=0.0129]\u001b[A\n",
            "Training Epoch 10:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.996, loss=0.0129]\u001b[A\n",
            "Training Epoch 10:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.995, loss=0.0171]\u001b[A\n",
            "Training Epoch 10:  50%|████▉     | 1844/3689 [05:24<05:13,  5.89batch/s, accuracy=0.995, loss=0.0171]\u001b[A\n",
            "Training Epoch 10:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.995, loss=0.0171]\u001b[A\n",
            "Training Epoch 10:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.994, loss=0.0198]\u001b[A\n",
            "Training Epoch 10:  75%|███████▍  | 2766/3689 [08:04<02:36,  5.90batch/s, accuracy=0.994, loss=0.0198]\u001b[A\n",
            "Training Epoch 10: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.994, loss=0.0198]\u001b[A\n",
            "Training Epoch 10: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.89batch/s, accuracy=0.994, loss=0.0211]\n",
            "\n",
            "Validation Epoch 10:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 10:  50%|████▉     | 790/1581 [00:46<00:46, 17.06batch/s]\u001b[A\n",
            "Validation Epoch 10:  50%|████▉     | 790/1581 [00:46<00:46, 17.06batch/s, accuracy=0.966, loss=0.162]\u001b[A\n",
            "Validation Epoch 10:  50%|████▉     | 790/1581 [00:57<00:46, 17.06batch/s, accuracy=0.966, loss=0.162]\u001b[A\n",
            "Validation Epoch 10: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.05batch/s, accuracy=0.966, loss=0.162]\u001b[A\n",
            "Validation Epoch 10: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.04batch/s, accuracy=0.966, loss=0.162]\n",
            "\n",
            "Training Epoch 11:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 11:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s]\u001b[A\n",
            "Training Epoch 11:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s, accuracy=0.993, loss=0.0185]\u001b[A\n",
            "Training Epoch 11:  25%|██▍       | 922/3689 [02:48<07:50,  5.89batch/s, accuracy=0.993, loss=0.0185]\u001b[A\n",
            "Training Epoch 11:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.993, loss=0.0185]\u001b[A\n",
            "Training Epoch 11:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.994, loss=0.0183]\u001b[A\n",
            "Training Epoch 11:  50%|████▉     | 1844/3689 [05:24<05:12,  5.90batch/s, accuracy=0.994, loss=0.0183]\u001b[A\n",
            "Training Epoch 11:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.994, loss=0.0183]\u001b[A\n",
            "Training Epoch 11:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.993, loss=0.0209]\u001b[A\n",
            "Training Epoch 11:  75%|███████▍  | 2766/3689 [08:04<02:36,  5.90batch/s, accuracy=0.993, loss=0.0209]\u001b[A\n",
            "Training Epoch 11: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.993, loss=0.0209]\u001b[A\n",
            "Training Epoch 11: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.993, loss=0.0208]\n",
            "\n",
            "Validation Epoch 11:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 11:  50%|████▉     | 790/1581 [00:46<00:46, 17.02batch/s]\u001b[A\n",
            "Validation Epoch 11:  50%|████▉     | 790/1581 [00:46<00:46, 17.02batch/s, accuracy=0.966, loss=0.169]\u001b[A\n",
            "Validation Epoch 11:  50%|████▉     | 790/1581 [00:57<00:46, 17.02batch/s, accuracy=0.966, loss=0.169]\u001b[A\n",
            "Validation Epoch 11: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.04batch/s, accuracy=0.966, loss=0.169]\u001b[A\n",
            "Validation Epoch 11: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.03batch/s, accuracy=0.967, loss=0.168]\n",
            "\n",
            "Training Epoch 12:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 12:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s]\u001b[A\n",
            "Training Epoch 12:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s, accuracy=0.996, loss=0.0123]\u001b[A\n",
            "Training Epoch 12:  25%|██▍       | 922/3689 [02:48<07:49,  5.89batch/s, accuracy=0.996, loss=0.0123]\u001b[A\n",
            "Training Epoch 12:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.996, loss=0.0123]\u001b[A\n",
            "Training Epoch 12:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.996, loss=0.0131]\u001b[A\n",
            "Training Epoch 12:  50%|████▉     | 1844/3689 [05:25<05:13,  5.89batch/s, accuracy=0.996, loss=0.0131]\u001b[A\n",
            "Training Epoch 12:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.996, loss=0.0131]\u001b[A\n",
            "Training Epoch 12:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.995, loss=0.0153]\u001b[A\n",
            "Training Epoch 12:  75%|███████▍  | 2766/3689 [08:05<02:36,  5.90batch/s, accuracy=0.995, loss=0.0153]\u001b[A\n",
            "Training Epoch 12: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.995, loss=0.0153]\u001b[A\n",
            "Training Epoch 12: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.89batch/s, accuracy=0.994, loss=0.0169]\n",
            "\n",
            "Validation Epoch 12:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 12:  50%|████▉     | 790/1581 [00:46<00:46, 17.04batch/s]\u001b[A\n",
            "Validation Epoch 12:  50%|████▉     | 790/1581 [00:46<00:46, 17.04batch/s, accuracy=0.967, loss=0.178]\u001b[A\n",
            "Validation Epoch 12:  50%|████▉     | 790/1581 [00:58<00:46, 17.04batch/s, accuracy=0.967, loss=0.178]\u001b[A\n",
            "Validation Epoch 12: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.04batch/s, accuracy=0.967, loss=0.178]\u001b[A\n",
            "Validation Epoch 12: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.03batch/s, accuracy=0.966, loss=0.179]\n",
            "\n",
            "Training Epoch 13:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 13:  25%|██▍       | 922/3689 [02:36<07:50,  5.88batch/s]\u001b[A\n",
            "Training Epoch 13:  25%|██▍       | 922/3689 [02:36<07:50,  5.88batch/s, accuracy=0.995, loss=0.0162]\u001b[A\n",
            "Training Epoch 13:  25%|██▍       | 922/3689 [02:48<07:50,  5.88batch/s, accuracy=0.995, loss=0.0162]\u001b[A\n",
            "Training Epoch 13:  50%|████▉     | 1844/3689 [05:13<05:13,  5.89batch/s, accuracy=0.995, loss=0.0162]\u001b[A\n",
            "Training Epoch 13:  50%|████▉     | 1844/3689 [05:13<05:13,  5.89batch/s, accuracy=0.995, loss=0.0172]\u001b[A\n",
            "Training Epoch 13:  50%|████▉     | 1844/3689 [05:25<05:13,  5.89batch/s, accuracy=0.995, loss=0.0172]\u001b[A\n",
            "Training Epoch 13:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.995, loss=0.0172]\u001b[A\n",
            "Training Epoch 13:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.994, loss=0.0186]\u001b[A\n",
            "Training Epoch 13:  75%|███████▍  | 2766/3689 [08:05<02:36,  5.90batch/s, accuracy=0.994, loss=0.0186]\u001b[A\n",
            "Training Epoch 13: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.994, loss=0.0186]\u001b[A\n",
            "Training Epoch 13: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.89batch/s, accuracy=0.994, loss=0.0185]\n",
            "\n",
            "Validation Epoch 13:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 13:  50%|████▉     | 790/1581 [00:46<00:46, 17.04batch/s]\u001b[A\n",
            "Validation Epoch 13:  50%|████▉     | 790/1581 [00:46<00:46, 17.04batch/s, accuracy=0.966, loss=0.174]\u001b[A\n",
            "Validation Epoch 13:  50%|████▉     | 790/1581 [00:58<00:46, 17.04batch/s, accuracy=0.966, loss=0.174]\u001b[A\n",
            "Validation Epoch 13: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.05batch/s, accuracy=0.966, loss=0.174]\u001b[A\n",
            "Validation Epoch 13: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.04batch/s, accuracy=0.966, loss=0.177]\n",
            "\n",
            "Training Epoch 14:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 14:  25%|██▍       | 922/3689 [02:36<07:50,  5.88batch/s]\u001b[A\n",
            "Training Epoch 14:  25%|██▍       | 922/3689 [02:36<07:50,  5.88batch/s, accuracy=0.996, loss=0.0138]\u001b[A\n",
            "Training Epoch 14:  25%|██▍       | 922/3689 [02:49<07:50,  5.88batch/s, accuracy=0.996, loss=0.0138]\u001b[A\n",
            "Training Epoch 14:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.996, loss=0.0138]\u001b[A\n",
            "Training Epoch 14:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.996, loss=0.0152]\u001b[A\n",
            "Training Epoch 14:  50%|████▉     | 1844/3689 [05:25<05:13,  5.89batch/s, accuracy=0.996, loss=0.0152]\u001b[A\n",
            "Training Epoch 14:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.996, loss=0.0152]\u001b[A\n",
            "Training Epoch 14:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.995, loss=0.0174]\u001b[A\n",
            "Training Epoch 14:  75%|███████▍  | 2766/3689 [08:05<02:36,  5.90batch/s, accuracy=0.995, loss=0.0174]\u001b[A\n",
            "Training Epoch 14: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.995, loss=0.0174]\u001b[A\n",
            "Training Epoch 14: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.994, loss=0.0181]\n",
            "\n",
            "Validation Epoch 14:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 14:  50%|████▉     | 790/1581 [00:46<00:46, 17.03batch/s]\u001b[A\n",
            "Validation Epoch 14:  50%|████▉     | 790/1581 [00:46<00:46, 17.03batch/s, accuracy=0.968, loss=0.176]\u001b[A\n",
            "Validation Epoch 14:  50%|████▉     | 790/1581 [00:58<00:46, 17.03batch/s, accuracy=0.968, loss=0.176]\u001b[A\n",
            "Validation Epoch 14: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.04batch/s, accuracy=0.968, loss=0.176]\u001b[A\n",
            "Validation Epoch 14: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.03batch/s, accuracy=0.968, loss=0.177]\n",
            "\n",
            "Training Epoch 15:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 15:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s]\u001b[A\n",
            "Training Epoch 15:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s, accuracy=0.995, loss=0.0154]\u001b[A\n",
            "Training Epoch 15:  25%|██▍       | 922/3689 [02:49<07:50,  5.89batch/s, accuracy=0.995, loss=0.0154]\u001b[A\n",
            "Training Epoch 15:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.995, loss=0.0154]\u001b[A\n",
            "Training Epoch 15:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.995, loss=0.0147]\u001b[A\n",
            "Training Epoch 15:  50%|████▉     | 1844/3689 [05:26<05:13,  5.89batch/s, accuracy=0.995, loss=0.0147]\u001b[A\n",
            "Training Epoch 15:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.995, loss=0.0147]\u001b[A\n",
            "Training Epoch 15:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.995, loss=0.0153]\u001b[A\n",
            "Training Epoch 15:  75%|███████▍  | 2766/3689 [07:59<02:36,  5.90batch/s, accuracy=0.995, loss=0.0153]\u001b[A\n",
            "Training Epoch 15: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.995, loss=0.0153]\u001b[A\n",
            "Training Epoch 15: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.995, loss=0.0148]\n",
            "\n",
            "Validation Epoch 15:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 15:  50%|████▉     | 790/1581 [00:46<00:46, 17.05batch/s]\u001b[A\n",
            "Validation Epoch 15:  50%|████▉     | 790/1581 [00:46<00:46, 17.05batch/s, accuracy=0.968, loss=0.18]\u001b[A\n",
            "Validation Epoch 15:  50%|████▉     | 790/1581 [00:59<00:46, 17.05batch/s, accuracy=0.968, loss=0.18]\u001b[A\n",
            "Validation Epoch 15: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.04batch/s, accuracy=0.968, loss=0.18]\u001b[A\n",
            "Validation Epoch 15: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.03batch/s, accuracy=0.967, loss=0.18]\n",
            "\n",
            "Training Epoch 16:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 16:  25%|██▍       | 922/3689 [02:36<07:50,  5.88batch/s]\u001b[A\n",
            "Training Epoch 16:  25%|██▍       | 922/3689 [02:36<07:50,  5.88batch/s, accuracy=0.996, loss=0.013]\u001b[A\n",
            "Training Epoch 16:  25%|██▍       | 922/3689 [02:50<07:50,  5.88batch/s, accuracy=0.996, loss=0.013]\u001b[A\n",
            "Training Epoch 16:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.996, loss=0.013]\u001b[A\n",
            "Training Epoch 16:  50%|████▉     | 1844/3689 [05:12<05:13,  5.89batch/s, accuracy=0.995, loss=0.013]\u001b[A\n",
            "Training Epoch 16:  50%|████▉     | 1844/3689 [05:26<05:13,  5.89batch/s, accuracy=0.995, loss=0.013]\u001b[A\n",
            "Training Epoch 16:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.995, loss=0.013]\u001b[A\n",
            "Training Epoch 16:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.995, loss=0.0141]\u001b[A\n",
            "Training Epoch 16:  75%|███████▍  | 2766/3689 [08:00<02:36,  5.90batch/s, accuracy=0.995, loss=0.0141]\u001b[A\n",
            "Training Epoch 16: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.995, loss=0.0141]\u001b[A\n",
            "Training Epoch 16: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.995, loss=0.0149]\n",
            "\n",
            "Validation Epoch 16:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 16:  50%|████▉     | 790/1581 [00:46<00:46, 17.04batch/s]\u001b[A\n",
            "Validation Epoch 16:  50%|████▉     | 790/1581 [00:46<00:46, 17.04batch/s, accuracy=0.968, loss=0.183]\u001b[A\n",
            "Validation Epoch 16:  50%|████▉     | 790/1581 [01:00<00:46, 17.04batch/s, accuracy=0.968, loss=0.183]\u001b[A\n",
            "Validation Epoch 16: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.04batch/s, accuracy=0.968, loss=0.183]\u001b[A\n",
            "Validation Epoch 16: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.03batch/s, accuracy=0.967, loss=0.182]\n",
            "\n",
            "Training Epoch 17:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 17:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s]\u001b[A\n",
            "Training Epoch 17:  25%|██▍       | 922/3689 [02:36<07:49,  5.89batch/s, accuracy=0.997, loss=0.0105]\u001b[A\n",
            "Training Epoch 17:  25%|██▍       | 922/3689 [02:47<07:49,  5.89batch/s, accuracy=0.997, loss=0.0105]\u001b[A\n",
            "Training Epoch 17:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.997, loss=0.0105]\u001b[A\n",
            "Training Epoch 17:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.996, loss=0.0122]\u001b[A\n",
            "Training Epoch 17:  50%|████▉     | 1844/3689 [05:27<05:12,  5.90batch/s, accuracy=0.996, loss=0.0122]\u001b[A\n",
            "Training Epoch 17:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.996, loss=0.0122]\u001b[A\n",
            "Training Epoch 17:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.995, loss=0.0123]\u001b[A\n",
            "Training Epoch 17:  75%|███████▍  | 2766/3689 [08:00<02:36,  5.90batch/s, accuracy=0.995, loss=0.0123]\u001b[A\n",
            "Training Epoch 17: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.995, loss=0.0123]\u001b[A\n",
            "Training Epoch 17: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.89batch/s, accuracy=0.995, loss=0.0128]\n",
            "\n",
            "Validation Epoch 17:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 17:  50%|████▉     | 790/1581 [00:46<00:46, 17.04batch/s]\u001b[A\n",
            "Validation Epoch 17:  50%|████▉     | 790/1581 [00:46<00:46, 17.04batch/s, accuracy=0.968, loss=0.192]\u001b[A\n",
            "Validation Epoch 17:  50%|████▉     | 790/1581 [01:00<00:46, 17.04batch/s, accuracy=0.968, loss=0.192]\u001b[A\n",
            "Validation Epoch 17: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.06batch/s, accuracy=0.968, loss=0.192]\u001b[A\n",
            "Validation Epoch 17: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.04batch/s, accuracy=0.969, loss=0.187]\n",
            "\n",
            "Training Epoch 18:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 18:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s]\u001b[A\n",
            "Training Epoch 18:  25%|██▍       | 922/3689 [02:36<07:50,  5.89batch/s, accuracy=0.995, loss=0.0112]\u001b[A\n",
            "Training Epoch 18:  25%|██▍       | 922/3689 [02:47<07:50,  5.89batch/s, accuracy=0.995, loss=0.0112]\u001b[A\n",
            "Training Epoch 18:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.995, loss=0.0112]\u001b[A\n",
            "Training Epoch 18:  50%|████▉     | 1844/3689 [05:12<05:12,  5.90batch/s, accuracy=0.994, loss=0.0149]\u001b[A\n",
            "Training Epoch 18:  50%|████▉     | 1844/3689 [05:27<05:12,  5.90batch/s, accuracy=0.994, loss=0.0149]\u001b[A\n",
            "Training Epoch 18:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.994, loss=0.0149]\u001b[A\n",
            "Training Epoch 18:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.90batch/s, accuracy=0.994, loss=0.0154]\u001b[A\n",
            "Training Epoch 18:  75%|███████▍  | 2766/3689 [08:01<02:36,  5.90batch/s, accuracy=0.994, loss=0.0154]\u001b[A\n",
            "Training Epoch 18: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.994, loss=0.0154]\u001b[A\n",
            "Training Epoch 18: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.995, loss=0.0139]\n",
            "\n",
            "Validation Epoch 18:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 18:  50%|████▉     | 790/1581 [00:46<00:46, 17.06batch/s]\u001b[A\n",
            "Validation Epoch 18:  50%|████▉     | 790/1581 [00:46<00:46, 17.06batch/s, accuracy=0.968, loss=0.2]\u001b[A\n",
            "Validation Epoch 18:  50%|████▉     | 790/1581 [01:01<00:46, 17.06batch/s, accuracy=0.968, loss=0.2]\u001b[A\n",
            "Validation Epoch 18: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.04batch/s, accuracy=0.968, loss=0.2]\u001b[A\n",
            "Validation Epoch 18: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.03batch/s, accuracy=0.969, loss=0.19]\n",
            "\n",
            "Training Epoch 19:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 19:  25%|██▍       | 922/3689 [02:36<07:50,  5.88batch/s]\u001b[A\n",
            "Training Epoch 19:  25%|██▍       | 922/3689 [02:36<07:50,  5.88batch/s, accuracy=0.997, loss=0.00881]\u001b[A\n",
            "Training Epoch 19:  25%|██▍       | 922/3689 [02:48<07:50,  5.88batch/s, accuracy=0.997, loss=0.00881]\u001b[A\n",
            "Training Epoch 19:  50%|████▉     | 1844/3689 [05:13<05:13,  5.89batch/s, accuracy=0.997, loss=0.00881]\u001b[A\n",
            "Training Epoch 19:  50%|████▉     | 1844/3689 [05:13<05:13,  5.89batch/s, accuracy=0.996, loss=0.0107] \u001b[A\n",
            "Training Epoch 19:  50%|████▉     | 1844/3689 [05:28<05:13,  5.89batch/s, accuracy=0.996, loss=0.0107]\u001b[A\n",
            "Training Epoch 19:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.89batch/s, accuracy=0.996, loss=0.0107]\u001b[A\n",
            "Training Epoch 19:  75%|███████▍  | 2766/3689 [07:49<02:36,  5.89batch/s, accuracy=0.996, loss=0.0121]\u001b[A\n",
            "Training Epoch 19:  75%|███████▍  | 2766/3689 [08:01<02:36,  5.89batch/s, accuracy=0.996, loss=0.0121]\u001b[A\n",
            "Training Epoch 19: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.90batch/s, accuracy=0.996, loss=0.0121]\u001b[A\n",
            "Training Epoch 19: 100%|█████████▉| 3688/3689 [10:25<00:00,  5.89batch/s, accuracy=0.995, loss=0.0125]\n",
            "\n",
            "Validation Epoch 19:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 19:  50%|████▉     | 790/1581 [00:46<00:46, 17.01batch/s]\u001b[A\n",
            "Validation Epoch 19:  50%|████▉     | 790/1581 [00:46<00:46, 17.01batch/s, accuracy=0.965, loss=0.191]\u001b[A\n",
            "Validation Epoch 19:  50%|████▉     | 790/1581 [01:01<00:46, 17.01batch/s, accuracy=0.965, loss=0.191]\u001b[A\n",
            "Validation Epoch 19: 100%|█████████▉| 1580/1581 [01:32<00:00, 17.00batch/s, accuracy=0.965, loss=0.191]\u001b[A\n",
            "Validation Epoch 19: 100%|█████████▉| 1580/1581 [01:32<00:00, 16.99batch/s, accuracy=0.967, loss=0.184]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 및 검증 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 지표 출력 및 저장\n",
        "metrics = {\n",
        "    'model_name': model_name,\n",
        "    'train_accuracy': train_accuracies,\n",
        "    'val_accuracy': val_accuracies,\n",
        "    'train_loss': train_losses,\n",
        "    'val_loss': val_losses,\n",
        "    'precision': precisions,\n",
        "    'recall': recalls,\n",
        "    'f1_score': f1_scores\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame([metrics])\n",
        "metrics_df.to_csv('klue_metrics.csv', index=False)\n",
        "print(\"klue_metrics saved.\")\n",
        "files.download('klue_metrics.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LSwqWdCjK_aO",
        "outputId": "b86787e9-ed5f-4286-bfd7-58395597d9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "klue_metrics saved.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e36a43fe-6aa7-4a4a-84ac-ad0b2d301705\", \"klue_metrics.csv\", 2955)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **koelectra 모델 학습**"
      ],
      "metadata": {
        "id": "flcq61CI2pJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, ElectraForSequenceClassification, AdamW\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "# GPU 사용 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "VPQabl1aTf3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 클래스 정의\n",
        "class LegalDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = eval(self.data.iloc[idx]['tokens_koelectra'])  # 토큰화된 데이터를 리스트로 변환\n",
        "        tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "        label = torch.tensor(self.data.iloc[idx]['label'], dtype=torch.long)\n",
        "        return tokens, label\n",
        "\n",
        "# 모델과 토크나이저 불러오기\n",
        "model_name = 'monologg/koelectra-base-v3-discriminator'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=13)\n",
        "model.to(device)  # 모델을 GPU로 전송"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3f21c38abdcb4c3fb9287dfc37849e86",
            "2d57a8348c0b4f9fbf3033476ccb79a9",
            "be579efe5b2540b898f90756b6317485",
            "459e05de755e4d0390b3b1bf8c3a1980",
            "648fa4f5b77942189fc0de4a5d3cdab0",
            "77baee453bd54a6f8df5a2ba3ae2210c",
            "7e92108741a442749fe3804733699218",
            "b0eef46d79c1477bbea37f403b5c05f2",
            "62bf930b8b2a4fc8bb81c2db1cf68a18",
            "65069c5c10c64321b6ae9ffa7fddb7a2",
            "f83a755d8bc942d39ce88d1f8f2e611b",
            "4851b43836c7457da4cfaea19a393bc0",
            "304c9225b3a74089bceab5e3bacc1525",
            "bbcd332037cd42f2acc2d10408c222f5",
            "8e210212fdb84408898a07a82c0174b8",
            "3dd0882b8fc24734863c5ed948e9bf84",
            "99f502761aeb4e428db564b182aca7f0",
            "c324bceb7cbf44e1b903bd8c3840f761",
            "3e5b7c136dd04521ab89e28cdebc7327",
            "f516712b1be540aab80d9cc14a883989",
            "11dd14703ff7491f96de49291837efe3",
            "b03afb135ca24c8da6e0b52fab60081f",
            "3e6fd0084d304d67be49f6f7776343a5",
            "be8a47f0aa224603bb4dd787d017025f",
            "25a46b08a9d24a6aad03d569c22254e5",
            "82d9d2be19d54a559bf771ea445e596f",
            "601acfb81aa34992bf0c4cbd02104748",
            "7a3f06551763458a98d36e62f32c7d2c",
            "440a606661ed4fd5bfb0eae0a9b73747",
            "1eb279f6deb64fe3a427da7c2e6a8ac1",
            "f6fececd07644ce4907b9dd53dd45774",
            "cb44fe7691894b3d88e5262e2becbb7e",
            "ae3222e2090b4211867c704932c8d509",
            "3882038a3a2a49479696c3f3be1be2f3",
            "d6860da6727641f2a62d4bcc8646887b",
            "6a78ad8937934f6ab22e3899c3fad89e",
            "c512eb8cecfb4f9a8e7322959eaba4be",
            "60d03cd1c25948b18c0dc93378396931",
            "ec173feed38a494297063f4be9e05a9f",
            "aa10eaf11a3847eb98a65bc3ec91c32d",
            "ec0d95917f3842dea67e36e335345391",
            "95d73173009949b6bf88e0d8add6c866",
            "ea9f6986cd174324b411df635c73b0e3",
            "293d0565fbf740b1bd6d16da6ca338de"
          ]
        },
        "collapsed": true,
        "id": "xsPlCCt8T5RW",
        "outputId": "97301182-e578-43c0-a76d-a09d481f8194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f21c38abdcb4c3fb9287dfc37849e86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/263k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4851b43836c7457da4cfaea19a393bc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e6fd0084d304d67be49f6f7776343a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'ElectraTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/452M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3882038a3a2a49479696c3f3be1be2f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): GELUActivation()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=13, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 미리 토큰화된 데이터 불러오기\n",
        "df = pd.read_csv('/content/drive/MyDrive/df_koelectra.csv')\n",
        "\n",
        "# 빈 리스트([])가 있는 행 제거\n",
        "df = df[df['tokens_koelectra'].apply(lambda x: len(eval(x)) > 0)]\n",
        "\n",
        "# '판결유형' 컬럼을 라벨로 변환\n",
        "label_map = {'민사_승소': 0, '민사_패소': 1, '민사_기각': 2, '징역': 3, '무혐의': 4, '벌금': 5, '형사_기각': 6, '가사_승소': 7, '가사_패소': 8, '가사_기각': 9, '세무_승소': 10, '세무_패소': 11, '세무_기각': 12}\n",
        "df['label'] = df['판결유형'].map(label_map)\n",
        "\n",
        "print(\"빈 리스트 제거 및 데이터 불러오기 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF2tm2oFT5M6",
        "outputId": "2fd135b0-7311-4c3d-bbdc-a6412ef2b0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈 리스트 제거 및 데이터 불러오기 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-cdd664adaba5>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = df['판결유형'].map(label_map)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 7:3 비율로 분리\n",
        "train_data = df.sample(frac=0.7, random_state=42)\n",
        "valid_data = df.drop(train_data.index)\n",
        "\n",
        "# 학습 데이터셋과 데이터로더 정의\n",
        "train_dataset = LegalDataset(train_data)\n",
        "valid_dataset = LegalDataset(valid_data)\n",
        "\n",
        "# 데이터로더 정의 시 collate_fn 추가\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Optimizer 설정\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsYQye3YT5Ht",
        "outputId": "2770e90e-8bb5-42aa-83b2-1a7a79ed67b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    tokens, labels = zip(*batch)\n",
        "\n",
        "    # 각 샘플의 tokens 길이를 512로 고정\n",
        "    max_length = 512\n",
        "\n",
        "    # 각 샘플의 tokens 길이가 다를 수 있으므로 패딩 적용 (최대 길이로 고정)\n",
        "    tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
        "\n",
        "    # Attention mask 추가 (패딩된 토큰을 0으로, 나머지를 1로 설정)\n",
        "    attention_mask = (tokens_padded != tokenizer.pad_token_id).long()\n",
        "\n",
        "    labels = torch.tensor(labels, dtype=torch.long)  # 라벨도 long 타입으로 변환\n",
        "\n",
        "    # 3개의 값을 반환해야 함: tokens_padded, attention_mask, labels\n",
        "    return tokens_padded, attention_mask, labels"
      ],
      "metadata": {
        "id": "h52iitYqXY3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    total_batches = len(loader)\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    # tqdm을 전체 에포크 단위로 초기화\n",
        "    progress_bar = tqdm(total=total_batches, desc=f\"Training Epoch {epoch}\", unit='batch', dynamic_ncols=True)\n",
        "\n",
        "    for batch_idx, (tokens, attention_mask, labels) in enumerate(loader):\n",
        "        tokens, attention_mask, labels = tokens.to(device), attention_mask.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=tokens, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += (outputs.logits.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "        # 예측 값과 실제 라벨 저장\n",
        "        all_preds.extend(outputs.logits.argmax(dim=1).detach().cpu().numpy())\n",
        "        all_labels.extend(labels.detach().cpu().numpy())\n",
        "\n",
        "        # 25%마다 진행 상황 업데이트\n",
        "        if (batch_idx + 1) % (total_batches // 4) == 0:\n",
        "            progress_bar.update(total_batches // 4)\n",
        "            progress_bar.set_postfix(loss=total_loss / (batch_idx + 1), accuracy=total_correct / ((batch_idx + 1) * loader.batch_size))\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    accuracy = total_correct / len(loader.dataset)\n",
        "\n",
        "    # Precision, Recall, F1-score 계산\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1\n",
        "\n",
        "def validate(model, loader, epoch):\n",
        "    model.eval()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    total_batches = len(loader)\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    progress_bar = tqdm(total=total_batches, desc=f\"Validation Epoch {epoch}\", unit='batch', dynamic_ncols=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (tokens, attention_mask, labels) in enumerate(loader):\n",
        "            tokens, attention_mask, labels = tokens.to(device), attention_mask.to(device), labels.to(device)\n",
        "            outputs = model(input_ids=tokens, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += (outputs.logits.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "            # 예측 값과 실제 라벨 저장\n",
        "            all_preds.extend(outputs.logits.argmax(dim=1).detach().cpu().numpy())\n",
        "            all_labels.extend(labels.detach().cpu().numpy())\n",
        "\n",
        "            # 50%마다 진행 상황 업데이트\n",
        "            if (batch_idx + 1) % (total_batches // 2) == 0:\n",
        "                progress_bar.update(total_batches // 2)\n",
        "                progress_bar.set_postfix(loss=total_loss / (batch_idx + 1), accuracy=total_correct / ((batch_idx + 1) * loader.batch_size))\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    accuracy = total_correct / len(loader.dataset)\n",
        "\n",
        "    # Precision, Recall, F1-score 계산\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "Fead20a9Tfpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 및 검증 진행\n",
        "best_val_loss = float('inf')\n",
        "train_accuracies, val_accuracies = [], []\n",
        "train_losses, val_losses = [], []\n",
        "precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "for epoch in range(20):\n",
        "    train_loss, train_acc, train_precision, train_recall, train_f1 = train(model, train_loader, optimizer, epoch)\n",
        "    val_loss, val_acc, val_precision, val_recall, val_f1 = validate(model, valid_loader, epoch)\n",
        "\n",
        "    # 각 모델의 결과 저장\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "    precisions.append(val_precision)\n",
        "    recalls.append(val_recall)\n",
        "    f1_scores.append(val_f1)\n",
        "\n",
        "    # 조기 종료 및 모델 저장\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        # 폴더가 없으면 생성\n",
        "        if not os.path.exists(model_name):\n",
        "            os.makedirs(model_name)\n",
        "        # 모델 저장\n",
        "        torch.save(model.state_dict(), f'{model_name}/best_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtNZy23ZTqoo",
        "outputId": "992dc095-e2c6-44e5-a970-7a259c6a8d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training Epoch 0:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 0:  25%|██▍       | 922/3689 [02:58<08:56,  5.16batch/s]\u001b[A\n",
            "Training Epoch 0:  25%|██▍       | 922/3689 [02:58<08:56,  5.16batch/s, accuracy=0.69, loss=1.15]\u001b[A\n",
            "Training Epoch 0:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.69, loss=1.15]\u001b[A\n",
            "Training Epoch 0:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.63, loss=1.31]\u001b[A\n",
            "Training Epoch 0:  75%|███████▍  | 2766/3689 [08:56<02:58,  5.16batch/s, accuracy=0.63, loss=1.31]\u001b[A\n",
            "Training Epoch 0:  75%|███████▍  | 2766/3689 [08:56<02:58,  5.16batch/s, accuracy=0.612, loss=1.36]\u001b[A\n",
            "Training Epoch 0: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.612, loss=1.36]\u001b[A\n",
            "Training Epoch 0: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.601, loss=1.39]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 0:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 0:  50%|████▉     | 790/1581 [00:52<00:52, 15.01batch/s]\u001b[A\n",
            "Validation Epoch 0:  50%|████▉     | 790/1581 [00:52<00:52, 15.01batch/s, accuracy=0.504, loss=1.71]\u001b[A\n",
            "Validation Epoch 0:  50%|████▉     | 790/1581 [01:04<00:52, 15.01batch/s, accuracy=0.504, loss=1.71]\u001b[A\n",
            "Validation Epoch 0: 100%|█████████▉| 1580/1581 [01:45<00:00, 15.02batch/s, accuracy=0.504, loss=1.71]\u001b[A\n",
            "Validation Epoch 0: 100%|█████████▉| 1580/1581 [01:45<00:00, 15.01batch/s, accuracy=0.572, loss=1.47]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 1:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 1:  25%|██▍       | 922/3689 [02:58<08:56,  5.16batch/s]\u001b[A\n",
            "Training Epoch 1:  25%|██▍       | 922/3689 [02:58<08:56,  5.16batch/s, accuracy=0.574, loss=1.45]\u001b[A\n",
            "Training Epoch 1:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.574, loss=1.45]\u001b[A\n",
            "Training Epoch 1:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 1:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 1:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 1: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 1: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.46]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 1:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 1:  50%|████▉     | 790/1581 [00:52<00:52, 15.06batch/s]\u001b[A\n",
            "Validation Epoch 1:  50%|████▉     | 790/1581 [00:52<00:52, 15.06batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 1:  50%|████▉     | 790/1581 [01:04<00:52, 15.06batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 1: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.08batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 1: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.07batch/s, accuracy=0.572, loss=1.46]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 2:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 2:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s]\u001b[A\n",
            "Training Epoch 2:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s, accuracy=0.57, loss=1.46]\u001b[A\n",
            "Training Epoch 2:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.57, loss=1.46]\u001b[A\n",
            "Training Epoch 2:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.57, loss=1.46]\u001b[A\n",
            "Training Epoch 2:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.57, loss=1.46]\u001b[A\n",
            "Training Epoch 2:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.571, loss=1.45]\u001b[A\n",
            "Training Epoch 2: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.45]\u001b[A\n",
            "Training Epoch 2: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.46]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 2:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 2:  50%|████▉     | 790/1581 [00:52<00:52, 15.07batch/s]\u001b[A\n",
            "Validation Epoch 2:  50%|████▉     | 790/1581 [00:52<00:52, 15.07batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 2:  50%|████▉     | 790/1581 [01:03<00:52, 15.07batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 2: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.09batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 2: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.08batch/s, accuracy=0.572, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 3:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 3:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s]\u001b[A\n",
            "Training Epoch 3:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s, accuracy=0.569, loss=1.46]\u001b[A\n",
            "Training Epoch 3:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.569, loss=1.46]\u001b[A\n",
            "Training Epoch 3:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.573, loss=1.46]\u001b[A\n",
            "Training Epoch 3:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.573, loss=1.46]\u001b[A\n",
            "Training Epoch 3:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 3: 100%|█████████▉| 3688/3689 [11:53<00:00,  5.17batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 3: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.46]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 3:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 3:  50%|████▉     | 790/1581 [00:52<00:52, 15.05batch/s]\u001b[A\n",
            "Validation Epoch 3:  50%|████▉     | 790/1581 [00:52<00:52, 15.05batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 3:  50%|████▉     | 790/1581 [01:03<00:52, 15.05batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 3: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.08batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 3: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.07batch/s, accuracy=0.572, loss=1.46]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 4:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 4:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s]\u001b[A\n",
            "Training Epoch 4:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s, accuracy=0.568, loss=1.46]\u001b[A\n",
            "Training Epoch 4:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.568, loss=1.46]\u001b[A\n",
            "Training Epoch 4:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 4:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 4:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.58, loss=1.43] \u001b[A\n",
            "Training Epoch 4: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.58, loss=1.43]\u001b[A\n",
            "Training Epoch 4: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.619, loss=1.31]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 4:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 4:  50%|████▉     | 790/1581 [00:52<00:52, 15.06batch/s]\u001b[A\n",
            "Validation Epoch 4:  50%|████▉     | 790/1581 [00:52<00:52, 15.06batch/s, accuracy=0.676, loss=1.08]\u001b[A\n",
            "Validation Epoch 4:  50%|████▉     | 790/1581 [01:04<00:52, 15.06batch/s, accuracy=0.676, loss=1.08]\u001b[A\n",
            "Validation Epoch 4: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.08batch/s, accuracy=0.676, loss=1.08]\u001b[A\n",
            "Validation Epoch 4: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.07batch/s, accuracy=0.726, loss=0.948]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 5:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 5:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s]\u001b[A\n",
            "Training Epoch 5:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s, accuracy=0.719, loss=0.982]\u001b[A\n",
            "Training Epoch 5:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.719, loss=0.982]\u001b[A\n",
            "Training Epoch 5:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.726, loss=0.956]\u001b[A\n",
            "Training Epoch 5:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.726, loss=0.956]\u001b[A\n",
            "Training Epoch 5:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.685, loss=1.09] \u001b[A\n",
            "Training Epoch 5: 100%|█████████▉| 3688/3689 [11:53<00:00,  5.17batch/s, accuracy=0.685, loss=1.09]\u001b[A\n",
            "Training Epoch 5: 100%|█████████▉| 3688/3689 [11:53<00:00,  5.17batch/s, accuracy=0.657, loss=1.18]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 5:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 5:  50%|████▉     | 790/1581 [00:52<00:52, 15.06batch/s]\u001b[A\n",
            "Validation Epoch 5:  50%|████▉     | 790/1581 [00:52<00:52, 15.06batch/s, accuracy=0.504, loss=1.68]\u001b[A\n",
            "Validation Epoch 5:  50%|████▉     | 790/1581 [01:04<00:52, 15.06batch/s, accuracy=0.504, loss=1.68]\u001b[A\n",
            "Validation Epoch 5: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.09batch/s, accuracy=0.504, loss=1.68]\u001b[A\n",
            "Validation Epoch 5: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.08batch/s, accuracy=0.572, loss=1.46]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 6:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 6:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s]\u001b[A\n",
            "Training Epoch 6:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s, accuracy=0.571, loss=1.45]\u001b[A\n",
            "Training Epoch 6:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.571, loss=1.45]\u001b[A\n",
            "Training Epoch 6:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.609, loss=1.33]\u001b[A\n",
            "Training Epoch 6:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.609, loss=1.33]\u001b[A\n",
            "Training Epoch 6:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.641, loss=1.24]\u001b[A\n",
            "Training Epoch 6: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.641, loss=1.24]\u001b[A\n",
            "Training Epoch 6: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.664, loss=1.16]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 6:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 6:  50%|████▉     | 790/1581 [00:52<00:52, 15.04batch/s]\u001b[A\n",
            "Validation Epoch 6:  50%|████▉     | 790/1581 [00:52<00:52, 15.04batch/s, accuracy=0.677, loss=1.19]\u001b[A\n",
            "Validation Epoch 6:  50%|████▉     | 790/1581 [01:05<00:52, 15.04batch/s, accuracy=0.677, loss=1.19]\u001b[A\n",
            "Validation Epoch 6: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.07batch/s, accuracy=0.677, loss=1.19]\u001b[A\n",
            "Validation Epoch 6: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.05batch/s, accuracy=0.73, loss=1.06]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 7:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 7:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s]\u001b[A\n",
            "Training Epoch 7:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s, accuracy=0.723, loss=0.964]\u001b[A\n",
            "Training Epoch 7:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.723, loss=0.964]\u001b[A\n",
            "Training Epoch 7:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.725, loss=0.961]\u001b[A\n",
            "Training Epoch 7:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.725, loss=0.961]\u001b[A\n",
            "Training Epoch 7:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.728, loss=0.953]\u001b[A\n",
            "Training Epoch 7: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.728, loss=0.953]\u001b[A\n",
            "Training Epoch 7: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.73, loss=0.942]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 7:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 7:  50%|████▉     | 790/1581 [00:52<00:52, 15.05batch/s]\u001b[A\n",
            "Validation Epoch 7:  50%|████▉     | 790/1581 [00:52<00:52, 15.05batch/s, accuracy=0.678, loss=1.2]\u001b[A\n",
            "Validation Epoch 7:  50%|████▉     | 790/1581 [01:05<00:52, 15.05batch/s, accuracy=0.678, loss=1.2]\u001b[A\n",
            "Validation Epoch 7: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.06batch/s, accuracy=0.678, loss=1.2]\u001b[A\n",
            "Validation Epoch 7: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.05batch/s, accuracy=0.729, loss=1.06]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 8:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 8:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s]\u001b[A\n",
            "Training Epoch 8:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s, accuracy=0.737, loss=0.924]\u001b[A\n",
            "Training Epoch 8:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.737, loss=0.924]\u001b[A\n",
            "Training Epoch 8:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.733, loss=0.936]\u001b[A\n",
            "Training Epoch 8:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.733, loss=0.936]\u001b[A\n",
            "Training Epoch 8:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.731, loss=0.939]\u001b[A\n",
            "Training Epoch 8: 100%|█████████▉| 3688/3689 [11:53<00:00,  5.17batch/s, accuracy=0.731, loss=0.939]\u001b[A\n",
            "Training Epoch 8: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.73, loss=0.941]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 8:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 8:  50%|████▉     | 790/1581 [00:52<00:52, 15.07batch/s]\u001b[A\n",
            "Validation Epoch 8:  50%|████▉     | 790/1581 [00:52<00:52, 15.07batch/s, accuracy=0.677, loss=1.16]\u001b[A\n",
            "Validation Epoch 8:  50%|████▉     | 790/1581 [01:06<00:52, 15.07batch/s, accuracy=0.677, loss=1.16]\u001b[A\n",
            "Validation Epoch 8: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.09batch/s, accuracy=0.677, loss=1.16]\u001b[A\n",
            "Validation Epoch 8: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.08batch/s, accuracy=0.729, loss=1.02]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 9:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 9:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s]\u001b[A\n",
            "Training Epoch 9:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s, accuracy=0.73, loss=0.944]\u001b[A\n",
            "Training Epoch 9:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.73, loss=0.944]\u001b[A\n",
            "Training Epoch 9:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.729, loss=0.947]\u001b[A\n",
            "Training Epoch 9:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.729, loss=0.947]\u001b[A\n",
            "Training Epoch 9:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.73, loss=0.944] \u001b[A\n",
            "Training Epoch 9: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.73, loss=0.944]\u001b[A\n",
            "Training Epoch 9: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.731, loss=0.939]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 9:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 9:  50%|████▉     | 790/1581 [00:52<00:52, 14.98batch/s]\u001b[A\n",
            "Validation Epoch 9:  50%|████▉     | 790/1581 [00:52<00:52, 14.98batch/s, accuracy=0.677, loss=1.09]\u001b[A\n",
            "Validation Epoch 9:  50%|████▉     | 790/1581 [01:02<00:52, 14.98batch/s, accuracy=0.677, loss=1.09]\u001b[A\n",
            "Validation Epoch 9: 100%|█████████▉| 1580/1581 [01:45<00:00, 15.03batch/s, accuracy=0.677, loss=1.09]\u001b[A\n",
            "Validation Epoch 9: 100%|█████████▉| 1580/1581 [01:45<00:00, 15.01batch/s, accuracy=0.73, loss=0.949]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 10:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 10:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s]\u001b[A\n",
            "Training Epoch 10:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s, accuracy=0.733, loss=0.932]\u001b[A\n",
            "Training Epoch 10:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.733, loss=0.932]\u001b[A\n",
            "Training Epoch 10:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.734, loss=0.927]\u001b[A\n",
            "Training Epoch 10:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.734, loss=0.927]\u001b[A\n",
            "Training Epoch 10:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.732, loss=0.932]\u001b[A\n",
            "Training Epoch 10: 100%|█████████▉| 3688/3689 [11:53<00:00,  5.17batch/s, accuracy=0.732, loss=0.932]\u001b[A\n",
            "Training Epoch 10: 100%|█████████▉| 3688/3689 [11:53<00:00,  5.17batch/s, accuracy=0.731, loss=0.936]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 10:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 10:  50%|████▉     | 790/1581 [00:53<00:53, 14.88batch/s]\u001b[A\n",
            "Validation Epoch 10:  50%|████▉     | 790/1581 [00:53<00:53, 14.88batch/s, accuracy=0.669, loss=1.37]\u001b[A\n",
            "Validation Epoch 10:  50%|████▉     | 790/1581 [01:03<00:53, 14.88batch/s, accuracy=0.669, loss=1.37]\u001b[A\n",
            "Validation Epoch 10: 100%|█████████▉| 1580/1581 [01:45<00:00, 14.95batch/s, accuracy=0.669, loss=1.37]\u001b[A\n",
            "Validation Epoch 10: 100%|█████████▉| 1580/1581 [01:45<00:00, 14.93batch/s, accuracy=0.716, loss=1.27]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 11:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 11:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s]\u001b[A\n",
            "Training Epoch 11:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s, accuracy=0.58, loss=1.42]\u001b[A\n",
            "Training Epoch 11:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.58, loss=1.42]\u001b[A\n",
            "Training Epoch 11:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.579, loss=1.43]\u001b[A\n",
            "Training Epoch 11:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.579, loss=1.43]\u001b[A\n",
            "Training Epoch 11:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.574, loss=1.44]\u001b[A\n",
            "Training Epoch 11: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.574, loss=1.44]\u001b[A\n",
            "Training Epoch 11: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.573, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 11:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 11:  50%|████▉     | 790/1581 [00:52<00:52, 15.02batch/s]\u001b[A\n",
            "Validation Epoch 11:  50%|████▉     | 790/1581 [00:52<00:52, 15.02batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 11:  50%|████▉     | 790/1581 [01:03<00:52, 15.02batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 11: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.07batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 11: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.05batch/s, accuracy=0.572, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 12:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 12:  25%|██▍       | 922/3689 [02:58<08:56,  5.16batch/s]\u001b[A\n",
            "Training Epoch 12:  25%|██▍       | 922/3689 [02:58<08:56,  5.16batch/s, accuracy=0.57, loss=1.46]\u001b[A\n",
            "Training Epoch 12:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.57, loss=1.46]\u001b[A\n",
            "Training Epoch 12:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 12:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 12:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.572, loss=1.45]\u001b[A\n",
            "Training Epoch 12: 100%|█████████▉| 3688/3689 [11:53<00:00,  5.17batch/s, accuracy=0.572, loss=1.45]\u001b[A\n",
            "Training Epoch 12: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 12:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 12:  50%|████▉     | 790/1581 [00:52<00:52, 15.05batch/s]\u001b[A\n",
            "Validation Epoch 12:  50%|████▉     | 790/1581 [00:52<00:52, 15.05batch/s, accuracy=0.504, loss=1.65]\u001b[A\n",
            "Validation Epoch 12:  50%|████▉     | 790/1581 [01:04<00:52, 15.05batch/s, accuracy=0.504, loss=1.65]\u001b[A\n",
            "Validation Epoch 12: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.08batch/s, accuracy=0.504, loss=1.65]\u001b[A\n",
            "Validation Epoch 12: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.06batch/s, accuracy=0.572, loss=1.46]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 13:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 13:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s]\u001b[A\n",
            "Training Epoch 13:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s, accuracy=0.605, loss=1.25]\u001b[A\n",
            "Training Epoch 13:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.605, loss=1.25]\u001b[A\n",
            "Training Epoch 13:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.591, loss=1.35]\u001b[A\n",
            "Training Epoch 13:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.591, loss=1.35]\u001b[A\n",
            "Training Epoch 13:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.585, loss=1.39]\u001b[A\n",
            "Training Epoch 13: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.585, loss=1.39]\u001b[A\n",
            "Training Epoch 13: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.581, loss=1.4]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 13:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 13:  50%|████▉     | 790/1581 [00:52<00:52, 15.01batch/s]\u001b[A\n",
            "Validation Epoch 13:  50%|████▉     | 790/1581 [00:52<00:52, 15.01batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 13:  50%|████▉     | 790/1581 [01:05<00:52, 15.01batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 13: 100%|█████████▉| 1580/1581 [01:45<00:00, 15.04batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 13: 100%|█████████▉| 1580/1581 [01:45<00:00, 15.03batch/s, accuracy=0.572, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 14:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 14:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s]\u001b[A\n",
            "Training Epoch 14:  25%|██▍       | 922/3689 [02:58<08:55,  5.16batch/s, accuracy=0.573, loss=1.44]\u001b[A\n",
            "Training Epoch 14:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.573, loss=1.44]\u001b[A\n",
            "Training Epoch 14:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.571, loss=1.44]\u001b[A\n",
            "Training Epoch 14:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.571, loss=1.44]\u001b[A\n",
            "Training Epoch 14:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.576, loss=1.44]\u001b[A\n",
            "Training Epoch 14: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.17batch/s, accuracy=0.576, loss=1.44]\u001b[A\n",
            "Training Epoch 14: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.574, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 14:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 14:  50%|████▉     | 790/1581 [00:52<00:52, 15.06batch/s]\u001b[A\n",
            "Validation Epoch 14:  50%|████▉     | 790/1581 [00:52<00:52, 15.06batch/s, accuracy=0.504, loss=1.68]\u001b[A\n",
            "Validation Epoch 14:  50%|████▉     | 790/1581 [01:05<00:52, 15.06batch/s, accuracy=0.504, loss=1.68]\u001b[A\n",
            "Validation Epoch 14: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.08batch/s, accuracy=0.504, loss=1.68]\u001b[A\n",
            "Validation Epoch 14: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.06batch/s, accuracy=0.572, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 15:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 15:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s]\u001b[A\n",
            "Training Epoch 15:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s, accuracy=0.568, loss=1.46]\u001b[A\n",
            "Training Epoch 15:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.568, loss=1.46]\u001b[A\n",
            "Training Epoch 15:  50%|████▉     | 1844/3689 [05:57<05:57,  5.17batch/s, accuracy=0.568, loss=1.46]\u001b[A\n",
            "Training Epoch 15:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.568, loss=1.46]\u001b[A\n",
            "Training Epoch 15:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.569, loss=1.46]\u001b[A\n",
            "Training Epoch 15: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.569, loss=1.46]\u001b[A\n",
            "Training Epoch 15: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 15:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 15:  50%|████▉     | 790/1581 [00:52<00:52, 15.07batch/s]\u001b[A\n",
            "Validation Epoch 15:  50%|████▉     | 790/1581 [00:52<00:52, 15.07batch/s, accuracy=0.503, loss=1.66]\u001b[A\n",
            "Validation Epoch 15:  50%|████▉     | 790/1581 [01:06<00:52, 15.07batch/s, accuracy=0.503, loss=1.66]\u001b[A\n",
            "Validation Epoch 15: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.09batch/s, accuracy=0.503, loss=1.66]\u001b[A\n",
            "Validation Epoch 15: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.07batch/s, accuracy=0.572, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 16:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 16:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s]\u001b[A\n",
            "Training Epoch 16:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s, accuracy=0.564, loss=1.47]\u001b[A\n",
            "Training Epoch 16:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.564, loss=1.47]\u001b[A\n",
            "Training Epoch 16:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.569, loss=1.46]\u001b[A\n",
            "Training Epoch 16:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.569, loss=1.46]\u001b[A\n",
            "Training Epoch 16:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.572, loss=1.45]\u001b[A\n",
            "Training Epoch 16: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.572, loss=1.45]\u001b[A\n",
            "Training Epoch 16: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 16:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 16:  50%|████▉     | 790/1581 [00:52<00:52, 15.08batch/s]\u001b[A\n",
            "Validation Epoch 16:  50%|████▉     | 790/1581 [00:52<00:52, 15.08batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 16:  50%|████▉     | 790/1581 [01:07<00:52, 15.08batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 16: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.09batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 16: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.07batch/s, accuracy=0.572, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 17:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 17:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s]\u001b[A\n",
            "Training Epoch 17:  25%|██▍       | 922/3689 [02:58<08:55,  5.17batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 17:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.571, loss=1.46]\u001b[A\n",
            "Training Epoch 17:  50%|████▉     | 1844/3689 [05:56<05:57,  5.17batch/s, accuracy=0.573, loss=1.45]\u001b[A\n",
            "Training Epoch 17:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.573, loss=1.45]\u001b[A\n",
            "Training Epoch 17:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.17batch/s, accuracy=0.572, loss=1.45]\u001b[A\n",
            "Training Epoch 17: 100%|█████████▉| 3688/3689 [11:53<00:00,  5.17batch/s, accuracy=0.572, loss=1.45]\u001b[A\n",
            "Training Epoch 17: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 17:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 17:  50%|████▉     | 790/1581 [00:52<00:52, 14.99batch/s]\u001b[A\n",
            "Validation Epoch 17:  50%|████▉     | 790/1581 [00:52<00:52, 14.99batch/s, accuracy=0.504, loss=1.68]\u001b[A\n",
            "Validation Epoch 17:  50%|████▉     | 790/1581 [01:08<00:52, 14.99batch/s, accuracy=0.504, loss=1.68]\u001b[A\n",
            "Validation Epoch 17: 100%|█████████▉| 1580/1581 [01:45<00:00, 15.04batch/s, accuracy=0.504, loss=1.68]\u001b[A\n",
            "Validation Epoch 17: 100%|█████████▉| 1580/1581 [01:45<00:00, 15.02batch/s, accuracy=0.572, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 18:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 18:  25%|██▍       | 922/3689 [02:58<08:56,  5.16batch/s]\u001b[A\n",
            "Training Epoch 18:  25%|██▍       | 922/3689 [02:58<08:56,  5.16batch/s, accuracy=0.567, loss=1.45]\u001b[A\n",
            "Training Epoch 18:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.567, loss=1.45]\u001b[A\n",
            "Training Epoch 18:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.57, loss=1.46] \u001b[A\n",
            "Training Epoch 18:  75%|███████▍  | 2766/3689 [08:56<02:58,  5.16batch/s, accuracy=0.57, loss=1.46]\u001b[A\n",
            "Training Epoch 18:  75%|███████▍  | 2766/3689 [08:56<02:58,  5.16batch/s, accuracy=0.571, loss=1.45]\u001b[A\n",
            "Training Epoch 18: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.45]\u001b[A\n",
            "Training Epoch 18: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 18:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 18:  50%|████▉     | 790/1581 [00:52<00:52, 14.96batch/s]\u001b[A\n",
            "Validation Epoch 18:  50%|████▉     | 790/1581 [00:52<00:52, 14.96batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 18:  50%|████▉     | 790/1581 [01:08<00:52, 14.96batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 18: 100%|█████████▉| 1580/1581 [01:45<00:00, 14.96batch/s, accuracy=0.504, loss=1.66]\u001b[A\n",
            "Validation Epoch 18: 100%|█████████▉| 1580/1581 [01:45<00:00, 14.95batch/s, accuracy=0.572, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Training Epoch 19:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Training Epoch 19:  25%|██▍       | 922/3689 [02:58<08:56,  5.16batch/s]\u001b[A\n",
            "Training Epoch 19:  25%|██▍       | 922/3689 [02:58<08:56,  5.16batch/s, accuracy=0.572, loss=1.46]\u001b[A\n",
            "Training Epoch 19:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.572, loss=1.46]\u001b[A\n",
            "Training Epoch 19:  50%|████▉     | 1844/3689 [05:57<05:57,  5.16batch/s, accuracy=0.574, loss=1.45]\u001b[A\n",
            "Training Epoch 19:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.574, loss=1.45]\u001b[A\n",
            "Training Epoch 19:  75%|███████▍  | 2766/3689 [08:55<02:58,  5.16batch/s, accuracy=0.57, loss=1.46] \u001b[A\n",
            "Training Epoch 19: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.57, loss=1.46]\u001b[A\n",
            "Training Epoch 19: 100%|█████████▉| 3688/3689 [11:54<00:00,  5.16batch/s, accuracy=0.571, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Validation Epoch 19:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-35-7a7da8540b3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = pad_sequence([torch.tensor(token) for token in tokens], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
            "\n",
            "Validation Epoch 19:  50%|████▉     | 790/1581 [00:52<00:52, 15.04batch/s]\u001b[A\n",
            "Validation Epoch 19:  50%|████▉     | 790/1581 [00:52<00:52, 15.04batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 19:  50%|████▉     | 790/1581 [01:08<00:52, 15.04batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 19: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.08batch/s, accuracy=0.504, loss=1.67]\u001b[A\n",
            "Validation Epoch 19: 100%|█████████▉| 1580/1581 [01:44<00:00, 15.06batch/s, accuracy=0.572, loss=1.45]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 지표 출력 및 저장\n",
        "metrics_2 = {\n",
        "    'model_name': model_name,\n",
        "    'train_accuracy': train_accuracies,\n",
        "    'val_accuracy': val_accuracies,\n",
        "    'train_loss': train_losses,\n",
        "    'val_loss': val_losses,\n",
        "    'precision': precisions,\n",
        "    'recall': recalls,\n",
        "    'f1_score': f1_scores\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame([metrics_2])\n",
        "metrics_df.to_csv('koelectra_metrics.csv', index=False)\n",
        "print(\"koelectra_metrics saved.\")\n",
        "files.download(\"koelectra_metrics.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ST-MJvomUoZX",
        "outputId": "1925bc44-f3da-47ae-cf42-7278db2068a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "koelectra_metrics saved.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e7342f8e-85ea-43e8-bb53-fdcaa23ed685\", \"koelectra_metrics.csv\", 2961)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **KcBERT 모델 학습**"
      ],
      "metadata": {
        "id": "D2sHnaWV2sCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Svbrzgd0fg-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 클래스 정의\n",
        "class LegalDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = eval(self.data.iloc[idx]['tokens_KcBERT'])  # 토큰화된 데이터를 리스트로 변환\n",
        "        tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "        label = torch.tensor(self.data.iloc[idx]['label'], dtype=torch.long)  # 라벨을 적절하게 변환\n",
        "        return tokens, label\n",
        "\n",
        "# 패딩 함수 정의\n",
        "def collate_fn(batch):\n",
        "    tokens, labels = zip(*batch)\n",
        "\n",
        "    # 각 샘플의 tokens 길이를 300으로 고정\n",
        "    max_length = 300\n",
        "\n",
        "    # 각 샘플의 tokens 길이가 다를 수 있으므로 패딩 적용 (최대 길이로 고정)\n",
        "    tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
        "\n",
        "    # Attention mask 추가 (패딩된 토큰을 0으로, 나머지를 1로 설정)\n",
        "    attention_mask = (tokens_padded != tokenizer.pad_token_id).long()\n",
        "\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return tokens_padded, attention_mask, labels"
      ],
      "metadata": {
        "id": "nRJTFssZfg8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 토크나이저 불러오기\n",
        "model_name = 'beomi/KcBERT-base'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=13)\n",
        "model.to(device)\n",
        "\n",
        "# 미리 토큰화된 데이터 불러오기\n",
        "df = pd.read_csv('/content/drive/MyDrive/df_KcBERT.csv')\n",
        "\n",
        "# 'tokens_KcBERT' 열에서 빈 리스트가 있는지 확인하고 제거\n",
        "df = df[df['tokens_KcBERT'].apply(lambda x: len(eval(x)) > 0)]\n",
        "\n",
        "# '판결유형' 컬럼을 라벨로 변환\n",
        "label_map = {'민사_승소': 0, '민사_패소': 1, '민사_기각': 2, '징역': 3, '무혐의': 4, '벌금': 5, '형사_기각': 6, '가사_승소': 7, '가사_패소': 8, '가사_기각': 9, '세무_승소': 10, '세무_패소': 11, '세무_기각': 12}\n",
        "df['label'] = df['판결유형'].map(label_map)\n",
        "\n",
        "print(\"데이터 불러오기 및 라벨 변환 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367,
          "referenced_widgets": [
            "a3ee5be0f3a443e8a56f0b45423b8e17",
            "3e9ad70df96a41bc89cc1f836b719c8d",
            "e7ce43b208ae4c989bf9ab965a632ec1",
            "1616e4abe83f4a0e9dc06952bd75186a",
            "7e7f195af072462cb18e9740f06ecef6",
            "ab671af8b4b544e99a72159e8856fa6c",
            "6a1694ed7254464e83c312aeb43049d8",
            "204ea7853d164cb98c361e5360c7d087",
            "127bb70d41da497781035103822141fd",
            "af383932dc13436287802fa5e1ac9474",
            "46dd0446cf8748bdb3b87542f7fc8d6d",
            "fcade4d63bb546148478600239094772",
            "895a62b06af24fa987077ea5281607a7",
            "bf8190644cf24f0c9d488f6eee6f8cbe",
            "7445716486824700863ccb7abad9e8f9",
            "27047da3b94c45f089e71e45f8ef25c3",
            "55ff26cb86d4415b90a9670fdbb3cecd",
            "6f88c25a6d4f4749916ea7673c23c780",
            "ec2aaede99ab4a5ca510bffd53742a30",
            "c28f73e269b7497aba26ab1b6637b2a5",
            "e6671324188b4380a4bffd9e85d8108a",
            "18fb4ab0228a4e14b1a696e726e77e3e",
            "48a4774195c4412dbe800186ee969be7",
            "a8b25e08c434442793712525e0432c4a",
            "f219563df232449598d57cbe05dea469",
            "4ba7d33f3e5340639922b8f6b862457a",
            "06fc2cd7d34e4448bb3cea46c9589be9",
            "185ae509bb874938ad9465d47e8dcad1",
            "cf537a0d58ea424abd1fa2a02cea84d7",
            "97dcb3e575a44b7abc3c177f0ec027d1",
            "0c52b3d1049648a68e00bd7907116f35",
            "3c9228e3519b438c95dc82951cafd9f7",
            "33f34f6e4f1941fd94718813dfba0093",
            "044ed50696bd4b29820114354aa76a9f",
            "c3adafcfd1a94dc29b256f67aac90a6d",
            "307807e8871747f3bc508a6246c5d520",
            "83c63f76458c48df864541bb306c8ccc",
            "8e98383dcb444a16beb2ce0e3fb751b7",
            "cab3bc024d744cc4b1ec3ceddd161f3e",
            "155c0e91115c4abf8fa3c5aea844cc52",
            "3e320b1075e94673aac2d9bb12a0a399",
            "7799f23208e149e78e45e3d306907861",
            "8421206c15754ed184254466db635ddb",
            "ae5928448d6244c8af5083b01c879e0b"
          ]
        },
        "id": "eYE4CUg2fg5u",
        "outputId": "4d756d4b-7a0e-420e-de18-d491e9aa9600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3ee5be0f3a443e8a56f0b45423b8e17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/250k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcade4d63bb546148478600239094772"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48a4774195c4412dbe800186ee969be7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "044ed50696bd4b29820114354aa76a9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/KcBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 불러오기 및 라벨 변환 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-2cf4548bbfe3>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = df['판결유형'].map(label_map)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 7:3 비율로 분리\n",
        "train_data = df.sample(frac=0.7, random_state=42)\n",
        "valid_data = df.drop(train_data.index)\n",
        "\n",
        "# 학습 데이터셋과 데이터로더 정의\n",
        "train_dataset = LegalDataset(train_data)\n",
        "valid_dataset = LegalDataset(valid_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Optimizer 설정\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWNHUChJfg1K",
        "outputId": "32550061-40c2-4b8e-db01-f74e049fd4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수 정의\n",
        "def train(model, loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    total_batches = len(loader)\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    # tqdm을 전체 에포크 단위로 초기화\n",
        "    progress_bar = tqdm(total=total_batches, desc=f\"Training Epoch {epoch}\", unit='batch', dynamic_ncols=True, mininterval=1)\n",
        "\n",
        "    for batch_idx, (tokens, attention_mask, labels) in enumerate(loader):\n",
        "        tokens, attention_mask, labels = tokens.to(device), attention_mask.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=tokens, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.logits.argmax(dim=1)\n",
        "        total_correct += (preds == labels).sum().item()\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # 25%마다 진행 상황 업데이트\n",
        "        if (batch_idx + 1) % (total_batches // 4) == 0:\n",
        "            progress_bar.update(total_batches // 4)\n",
        "            progress_bar.set_postfix(loss=total_loss / (batch_idx + 1), accuracy=total_correct / ((batch_idx + 1) * loader.batch_size))\n",
        "\n",
        "    progress_bar.close()\n",
        "    avg_loss = total_loss / total_batches\n",
        "    accuracy = total_correct / len(loader.dataset)\n",
        "\n",
        "    # precision, recall, f1-score 계산\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1\n",
        "\n",
        "# 검증 함수 정의\n",
        "def validate(model, loader, epoch):\n",
        "    model.eval()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    total_batches = len(loader)\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    progress_bar = tqdm(total=total_batches, desc=f\"Validation Epoch {epoch}\", unit='batch', dynamic_ncols=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (tokens, attention_mask, labels) in enumerate(loader):\n",
        "            tokens, attention_mask, labels = tokens.to(device), attention_mask.to(device), labels.to(device)\n",
        "            outputs = model(input_ids=tokens, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            total_correct += (preds == labels).sum().item()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # 50%마다 진행 상황 업데이트\n",
        "            if (batch_idx + 1) % (total_batches // 2) == 0:\n",
        "                progress_bar.update(total_batches // 2)\n",
        "                progress_bar.set_postfix(loss=total_loss / (batch_idx + 1), accuracy=total_correct / ((batch_idx + 1) * loader.batch_size))\n",
        "\n",
        "    progress_bar.close()\n",
        "    avg_loss = total_loss / total_batches\n",
        "    accuracy = total_correct / len(loader.dataset)\n",
        "\n",
        "    # precision, recall, f1-score 계산\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "-uVuhvdufgy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 및 검증 함수 실행\n",
        "best_val_loss = float('inf')\n",
        "train_accuracies, val_accuracies = [], []\n",
        "train_losses, val_losses = [], []\n",
        "precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "for epoch in range(20):\n",
        "    train_loss, train_acc, train_precision, train_recall, train_f1 = train(model, train_loader, optimizer, epoch)\n",
        "    val_loss, val_acc, val_precision, val_recall, val_f1 = validate(model, valid_loader, epoch)\n",
        "\n",
        "    # 각 모델의 결과 저장\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "    precisions.append(val_precision)\n",
        "    recalls.append(val_recall)\n",
        "    f1_scores.append(val_f1)\n",
        "\n",
        "    # 조기 종료 및 모델 저장\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        # 폴더가 없으면 생성\n",
        "        if not os.path.exists(model_name):\n",
        "            os.makedirs(model_name)\n",
        "        # 모델 저장\n",
        "        torch.save(model.state_dict(), f'{model_name}/best_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpYj3Xw-fgwZ",
        "outputId": "6b310e1f-b275-40a0-e604-290db72b7f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training Epoch 0:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 0:  25%|██▍       | 922/3689 [01:39<04:58,  9.27batch/s]\u001b[A\n",
            "Training Epoch 0:  25%|██▍       | 922/3689 [01:39<04:58,  9.27batch/s, accuracy=0.886, loss=0.417]\u001b[A\n",
            "Training Epoch 0:  25%|██▍       | 922/3689 [01:55<04:58,  9.27batch/s, accuracy=0.886, loss=0.417]\u001b[A\n",
            "Training Epoch 0:  50%|████▉     | 1844/3689 [03:18<03:18,  9.28batch/s, accuracy=0.886, loss=0.417]\u001b[A\n",
            "Training Epoch 0:  50%|████▉     | 1844/3689 [03:18<03:18,  9.28batch/s, accuracy=0.91, loss=0.315] \u001b[A\n",
            "Training Epoch 0:  50%|████▉     | 1844/3689 [03:29<03:18,  9.28batch/s, accuracy=0.91, loss=0.315]\u001b[A\n",
            "Training Epoch 0:  75%|███████▍  | 2766/3689 [04:57<01:39,  9.29batch/s, accuracy=0.91, loss=0.315]\u001b[A\n",
            "Training Epoch 0:  75%|███████▍  | 2766/3689 [04:57<01:39,  9.29batch/s, accuracy=0.922, loss=0.27]\u001b[A\n",
            "Training Epoch 0:  75%|███████▍  | 2766/3689 [05:09<01:39,  9.29batch/s, accuracy=0.922, loss=0.27]\u001b[A\n",
            "Training Epoch 0: 100%|█████████▉| 3688/3689 [06:37<00:00,  9.29batch/s, accuracy=0.922, loss=0.27]\u001b[A\n",
            "Training Epoch 0: 100%|█████████▉| 3688/3689 [06:37<00:00,  9.29batch/s, accuracy=0.93, loss=0.238]\n",
            "\n",
            "Validation Epoch 0:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 0:  50%|████▉     | 790/1581 [00:31<00:31, 25.04batch/s]\u001b[A\n",
            "Validation Epoch 0:  50%|████▉     | 790/1581 [00:31<00:31, 25.04batch/s, accuracy=0.943, loss=0.186]\u001b[A\n",
            "Validation Epoch 0:  50%|████▉     | 790/1581 [00:42<00:31, 25.04batch/s, accuracy=0.943, loss=0.186]\u001b[A\n",
            "Validation Epoch 0: 100%|█████████▉| 1580/1581 [01:02<00:00, 25.13batch/s, accuracy=0.943, loss=0.186]\u001b[A\n",
            "Validation Epoch 0: 100%|█████████▉| 1580/1581 [01:02<00:00, 25.10batch/s, accuracy=0.959, loss=0.133]\n",
            "\n",
            "Training Epoch 1:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 1:  25%|██▍       | 922/3689 [01:39<04:57,  9.29batch/s]\u001b[A\n",
            "Training Epoch 1:  25%|██▍       | 922/3689 [01:39<04:57,  9.29batch/s, accuracy=0.958, loss=0.127]\u001b[A\n",
            "Training Epoch 1:  25%|██▍       | 922/3689 [01:54<04:57,  9.29batch/s, accuracy=0.958, loss=0.127]\u001b[A\n",
            "Training Epoch 1:  50%|████▉     | 1844/3689 [03:18<03:18,  9.30batch/s, accuracy=0.958, loss=0.127]\u001b[A\n",
            "Training Epoch 1:  50%|████▉     | 1844/3689 [03:18<03:18,  9.30batch/s, accuracy=0.956, loss=0.132]\u001b[A\n",
            "Training Epoch 1:  50%|████▉     | 1844/3689 [03:28<03:18,  9.30batch/s, accuracy=0.956, loss=0.132]\u001b[A\n",
            "Training Epoch 1:  75%|███████▍  | 2766/3689 [04:57<01:39,  9.29batch/s, accuracy=0.956, loss=0.132]\u001b[A\n",
            "Training Epoch 1:  75%|███████▍  | 2766/3689 [04:57<01:39,  9.29batch/s, accuracy=0.957, loss=0.133]\u001b[A\n",
            "Training Epoch 1:  75%|███████▍  | 2766/3689 [05:08<01:39,  9.29batch/s, accuracy=0.957, loss=0.133]\u001b[A\n",
            "Training Epoch 1: 100%|█████████▉| 3688/3689 [06:36<00:00,  9.29batch/s, accuracy=0.957, loss=0.133]\u001b[A\n",
            "Training Epoch 1: 100%|█████████▉| 3688/3689 [06:36<00:00,  9.29batch/s, accuracy=0.957, loss=0.133]\n",
            "\n",
            "Validation Epoch 1:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 1:  50%|████▉     | 790/1581 [00:31<00:31, 25.11batch/s]\u001b[A\n",
            "Validation Epoch 1:  50%|████▉     | 790/1581 [00:31<00:31, 25.11batch/s, accuracy=0.946, loss=0.174]\u001b[A\n",
            "Validation Epoch 1:  50%|████▉     | 790/1581 [00:41<00:31, 25.11batch/s, accuracy=0.946, loss=0.174]\u001b[A\n",
            "Validation Epoch 1: 100%|█████████▉| 1580/1581 [01:02<00:00, 25.16batch/s, accuracy=0.946, loss=0.174]\u001b[A\n",
            "Validation Epoch 1: 100%|█████████▉| 1580/1581 [01:02<00:00, 25.14batch/s, accuracy=0.96, loss=0.127]\n",
            "\n",
            "Training Epoch 2:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 2:  25%|██▍       | 922/3689 [01:39<04:57,  9.30batch/s]\u001b[A\n",
            "Training Epoch 2:  25%|██▍       | 922/3689 [01:39<04:57,  9.30batch/s, accuracy=0.965, loss=0.106]\u001b[A\n",
            "Training Epoch 2:  25%|██▍       | 922/3689 [01:53<04:57,  9.30batch/s, accuracy=0.965, loss=0.106]\u001b[A\n",
            "Training Epoch 2:  50%|████▉     | 1844/3689 [03:18<03:18,  9.28batch/s, accuracy=0.965, loss=0.106]\u001b[A\n",
            "Training Epoch 2:  50%|████▉     | 1844/3689 [03:18<03:18,  9.28batch/s, accuracy=0.964, loss=0.11] \u001b[A\n",
            "Training Epoch 2:  50%|████▉     | 1844/3689 [03:33<03:18,  9.28batch/s, accuracy=0.964, loss=0.11]\u001b[A\n",
            "Training Epoch 2:  75%|███████▍  | 2766/3689 [04:57<01:39,  9.29batch/s, accuracy=0.964, loss=0.11]\u001b[A\n",
            "Training Epoch 2:  75%|███████▍  | 2766/3689 [04:57<01:39,  9.29batch/s, accuracy=0.963, loss=0.112]\u001b[A\n",
            "Training Epoch 2:  75%|███████▍  | 2766/3689 [05:13<01:39,  9.29batch/s, accuracy=0.963, loss=0.112]\u001b[A\n",
            "Training Epoch 2: 100%|█████████▉| 3688/3689 [06:37<00:00,  9.29batch/s, accuracy=0.963, loss=0.112]\u001b[A\n",
            "Training Epoch 2: 100%|█████████▉| 3688/3689 [06:37<00:00,  9.29batch/s, accuracy=0.962, loss=0.116]\n",
            "\n",
            "Validation Epoch 2:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 2:  50%|████▉     | 790/1581 [00:31<00:31, 25.08batch/s]\u001b[A\n",
            "Validation Epoch 2:  50%|████▉     | 790/1581 [00:31<00:31, 25.08batch/s, accuracy=0.944, loss=0.186]\u001b[A\n",
            "Validation Epoch 2:  50%|████▉     | 790/1581 [00:46<00:31, 25.08batch/s, accuracy=0.944, loss=0.186]\u001b[A\n",
            "Validation Epoch 2: 100%|█████████▉| 1580/1581 [01:02<00:00, 25.16batch/s, accuracy=0.944, loss=0.186]\u001b[A\n",
            "Validation Epoch 2: 100%|█████████▉| 1580/1581 [01:02<00:00, 25.13batch/s, accuracy=0.959, loss=0.142]\n",
            "\n",
            "Training Epoch 3:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 3:  25%|██▍       | 922/3689 [01:39<04:57,  9.30batch/s]\u001b[A\n",
            "Training Epoch 3:  25%|██▍       | 922/3689 [01:39<04:57,  9.30batch/s, accuracy=0.968, loss=0.099]\u001b[A\n",
            "Training Epoch 3:  25%|██▍       | 922/3689 [01:53<04:57,  9.30batch/s, accuracy=0.968, loss=0.099]\u001b[A\n",
            "Training Epoch 3:  50%|████▉     | 1844/3689 [03:18<03:18,  9.30batch/s, accuracy=0.968, loss=0.099]\u001b[A\n",
            "Training Epoch 3:  50%|████▉     | 1844/3689 [03:18<03:18,  9.30batch/s, accuracy=0.967, loss=0.101]\u001b[A\n",
            "Training Epoch 3:  50%|████▉     | 1844/3689 [03:33<03:18,  9.30batch/s, accuracy=0.967, loss=0.101]\u001b[A\n",
            "Training Epoch 3:  75%|███████▍  | 2766/3689 [04:58<01:39,  9.27batch/s, accuracy=0.967, loss=0.101]\u001b[A\n",
            "Training Epoch 3:  75%|███████▍  | 2766/3689 [04:58<01:39,  9.27batch/s, accuracy=0.968, loss=0.1]  \u001b[A\n",
            "Training Epoch 3:  75%|███████▍  | 2766/3689 [05:13<01:39,  9.27batch/s, accuracy=0.968, loss=0.1]\u001b[A\n",
            "Training Epoch 3: 100%|█████████▉| 3688/3689 [06:37<00:00,  9.26batch/s, accuracy=0.968, loss=0.1]\u001b[A\n",
            "Training Epoch 3: 100%|█████████▉| 3688/3689 [06:37<00:00,  9.27batch/s, accuracy=0.967, loss=0.101]\n",
            "\n",
            "Validation Epoch 3:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 3:  50%|████▉     | 790/1581 [00:31<00:31, 24.75batch/s]\u001b[A\n",
            "Validation Epoch 3:  50%|████▉     | 790/1581 [00:31<00:31, 24.75batch/s, accuracy=0.945, loss=0.184]\u001b[A\n",
            "Validation Epoch 3:  50%|████▉     | 790/1581 [00:45<00:31, 24.75batch/s, accuracy=0.945, loss=0.184]\u001b[A\n",
            "Validation Epoch 3: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.82batch/s, accuracy=0.945, loss=0.184]\u001b[A\n",
            "Validation Epoch 3: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.79batch/s, accuracy=0.96, loss=0.135]\n",
            "\n",
            "Training Epoch 4:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 4:  25%|██▍       | 922/3689 [01:39<04:59,  9.25batch/s]\u001b[A\n",
            "Training Epoch 4:  25%|██▍       | 922/3689 [01:39<04:59,  9.25batch/s, accuracy=0.973, loss=0.0827]\u001b[A\n",
            "Training Epoch 4:  25%|██▍       | 922/3689 [01:51<04:59,  9.25batch/s, accuracy=0.973, loss=0.0827]\u001b[A\n",
            "Training Epoch 4:  50%|████▉     | 1844/3689 [03:19<03:19,  9.25batch/s, accuracy=0.973, loss=0.0827]\u001b[A\n",
            "Training Epoch 4:  50%|████▉     | 1844/3689 [03:19<03:19,  9.25batch/s, accuracy=0.972, loss=0.0875]\u001b[A\n",
            "Training Epoch 4:  50%|████▉     | 1844/3689 [03:31<03:19,  9.25batch/s, accuracy=0.972, loss=0.0875]\u001b[A\n",
            "Training Epoch 4:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.25batch/s, accuracy=0.972, loss=0.0875]\u001b[A\n",
            "Training Epoch 4:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.25batch/s, accuracy=0.97, loss=0.0931] \u001b[A\n",
            "Training Epoch 4:  75%|███████▍  | 2766/3689 [05:12<01:39,  9.25batch/s, accuracy=0.97, loss=0.0931]\u001b[A\n",
            "Training Epoch 4: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.25batch/s, accuracy=0.97, loss=0.0931]\u001b[A\n",
            "Training Epoch 4: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.25batch/s, accuracy=0.969, loss=0.0944]\n",
            "\n",
            "Validation Epoch 4:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 4:  50%|████▉     | 790/1581 [00:31<00:31, 24.80batch/s]\u001b[A\n",
            "Validation Epoch 4:  50%|████▉     | 790/1581 [00:31<00:31, 24.80batch/s, accuracy=0.947, loss=0.17]\u001b[A\n",
            "Validation Epoch 4:  50%|████▉     | 790/1581 [00:43<00:31, 24.80batch/s, accuracy=0.947, loss=0.17]\u001b[A\n",
            "Validation Epoch 4: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.90batch/s, accuracy=0.947, loss=0.17]\u001b[A\n",
            "Validation Epoch 4: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.87batch/s, accuracy=0.963, loss=0.119]\n",
            "\n",
            "Training Epoch 5:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 5:  25%|██▍       | 922/3689 [01:39<04:59,  9.24batch/s]\u001b[A\n",
            "Training Epoch 5:  25%|██▍       | 922/3689 [01:39<04:59,  9.24batch/s, accuracy=0.973, loss=0.0782]\u001b[A\n",
            "Training Epoch 5:  25%|██▍       | 922/3689 [01:51<04:59,  9.24batch/s, accuracy=0.973, loss=0.0782]\u001b[A\n",
            "Training Epoch 5:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.973, loss=0.0782]\u001b[A\n",
            "Training Epoch 5:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.973, loss=0.0765]\u001b[A\n",
            "Training Epoch 5:  50%|████▉     | 1844/3689 [03:31<03:19,  9.24batch/s, accuracy=0.973, loss=0.0765]\u001b[A\n",
            "Training Epoch 5:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.973, loss=0.0765]\u001b[A\n",
            "Training Epoch 5:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.974, loss=0.0781]\u001b[A\n",
            "Training Epoch 5:  75%|███████▍  | 2766/3689 [05:11<01:39,  9.24batch/s, accuracy=0.974, loss=0.0781]\u001b[A\n",
            "Training Epoch 5: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.24batch/s, accuracy=0.974, loss=0.0781]\u001b[A\n",
            "Training Epoch 5: 100%|█████████▉| 3688/3689 [06:39<00:00,  9.24batch/s, accuracy=0.974, loss=0.0777]\n",
            "\n",
            "Validation Epoch 5:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 5:  50%|████▉     | 790/1581 [00:31<00:31, 24.84batch/s]\u001b[A\n",
            "Validation Epoch 5:  50%|████▉     | 790/1581 [00:31<00:31, 24.84batch/s, accuracy=0.946, loss=0.212]\u001b[A\n",
            "Validation Epoch 5:  50%|████▉     | 790/1581 [00:42<00:31, 24.84batch/s, accuracy=0.946, loss=0.212]\u001b[A\n",
            "Validation Epoch 5: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.83batch/s, accuracy=0.946, loss=0.212]\u001b[A\n",
            "Validation Epoch 5: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.81batch/s, accuracy=0.963, loss=0.151]\n",
            "\n",
            "Training Epoch 6:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 6:  25%|██▍       | 922/3689 [01:39<04:59,  9.25batch/s]\u001b[A\n",
            "Training Epoch 6:  25%|██▍       | 922/3689 [01:39<04:59,  9.25batch/s, accuracy=0.978, loss=0.0694]\u001b[A\n",
            "Training Epoch 6:  25%|██▍       | 922/3689 [01:54<04:59,  9.25batch/s, accuracy=0.978, loss=0.0694]\u001b[A\n",
            "Training Epoch 6:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.978, loss=0.0694]\u001b[A\n",
            "Training Epoch 6:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.98, loss=0.0661] \u001b[A\n",
            "Training Epoch 6:  50%|████▉     | 1844/3689 [03:34<03:19,  9.24batch/s, accuracy=0.98, loss=0.0661]\u001b[A\n",
            "Training Epoch 6:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.98, loss=0.0661]\u001b[A\n",
            "Training Epoch 6:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.978, loss=0.0688]\u001b[A\n",
            "Training Epoch 6:  75%|███████▍  | 2766/3689 [05:14<01:39,  9.24batch/s, accuracy=0.978, loss=0.0688]\u001b[A\n",
            "Training Epoch 6: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.25batch/s, accuracy=0.978, loss=0.0688]\u001b[A\n",
            "Training Epoch 6: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.25batch/s, accuracy=0.977, loss=0.0721]\n",
            "\n",
            "Validation Epoch 6:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 6:  50%|████▉     | 790/1581 [00:31<00:31, 24.90batch/s]\u001b[A\n",
            "Validation Epoch 6:  50%|████▉     | 790/1581 [00:31<00:31, 24.90batch/s, accuracy=0.952, loss=0.184]\u001b[A\n",
            "Validation Epoch 6:  50%|████▉     | 790/1581 [00:46<00:31, 24.90batch/s, accuracy=0.952, loss=0.184]\u001b[A\n",
            "Validation Epoch 6: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.97batch/s, accuracy=0.952, loss=0.184]\u001b[A\n",
            "Validation Epoch 6: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.94batch/s, accuracy=0.967, loss=0.129]\n",
            "\n",
            "Training Epoch 7:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 7:  25%|██▍       | 922/3689 [01:39<04:58,  9.26batch/s]\u001b[A\n",
            "Training Epoch 7:  25%|██▍       | 922/3689 [01:39<04:58,  9.26batch/s, accuracy=0.981, loss=0.0596]\u001b[A\n",
            "Training Epoch 7:  25%|██▍       | 922/3689 [01:52<04:58,  9.26batch/s, accuracy=0.981, loss=0.0596]\u001b[A\n",
            "Training Epoch 7:  50%|████▉     | 1844/3689 [03:19<03:19,  9.27batch/s, accuracy=0.981, loss=0.0596]\u001b[A\n",
            "Training Epoch 7:  50%|████▉     | 1844/3689 [03:19<03:19,  9.27batch/s, accuracy=0.981, loss=0.0602]\u001b[A\n",
            "Training Epoch 7:  50%|████▉     | 1844/3689 [03:32<03:19,  9.27batch/s, accuracy=0.981, loss=0.0602]\u001b[A\n",
            "Training Epoch 7:  75%|███████▍  | 2766/3689 [04:58<01:39,  9.25batch/s, accuracy=0.981, loss=0.0602]\u001b[A\n",
            "Training Epoch 7:  75%|███████▍  | 2766/3689 [04:58<01:39,  9.25batch/s, accuracy=0.981, loss=0.0608]\u001b[A\n",
            "Training Epoch 7:  75%|███████▍  | 2766/3689 [05:12<01:39,  9.25batch/s, accuracy=0.981, loss=0.0608]\u001b[A\n",
            "Training Epoch 7: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.27batch/s, accuracy=0.981, loss=0.0608]\u001b[A\n",
            "Training Epoch 7: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.26batch/s, accuracy=0.98, loss=0.0633]\n",
            "\n",
            "Validation Epoch 7:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 7:  50%|████▉     | 790/1581 [00:31<00:31, 25.06batch/s]\u001b[A\n",
            "Validation Epoch 7:  50%|████▉     | 790/1581 [00:31<00:31, 25.06batch/s, accuracy=0.945, loss=0.183]\u001b[A\n",
            "Validation Epoch 7:  50%|████▉     | 790/1581 [00:44<00:31, 25.06batch/s, accuracy=0.945, loss=0.183]\u001b[A\n",
            "Validation Epoch 7: 100%|█████████▉| 1580/1581 [01:02<00:00, 25.12batch/s, accuracy=0.945, loss=0.183]\u001b[A\n",
            "Validation Epoch 7: 100%|█████████▉| 1580/1581 [01:02<00:00, 25.09batch/s, accuracy=0.962, loss=0.13]\n",
            "\n",
            "Training Epoch 8:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 8:  25%|██▍       | 922/3689 [01:39<04:57,  9.30batch/s]\u001b[A\n",
            "Training Epoch 8:  25%|██▍       | 922/3689 [01:39<04:57,  9.30batch/s, accuracy=0.984, loss=0.0527]\u001b[A\n",
            "Training Epoch 8:  25%|██▍       | 922/3689 [01:51<04:57,  9.30batch/s, accuracy=0.984, loss=0.0527]\u001b[A\n",
            "Training Epoch 8:  50%|████▉     | 1844/3689 [03:18<03:18,  9.29batch/s, accuracy=0.984, loss=0.0527]\u001b[A\n",
            "Training Epoch 8:  50%|████▉     | 1844/3689 [03:18<03:18,  9.29batch/s, accuracy=0.984, loss=0.0513]\u001b[A\n",
            "Training Epoch 8:  50%|████▉     | 1844/3689 [03:31<03:18,  9.29batch/s, accuracy=0.984, loss=0.0513]\u001b[A\n",
            "Training Epoch 8:  75%|███████▍  | 2766/3689 [04:57<01:39,  9.28batch/s, accuracy=0.984, loss=0.0513]\u001b[A\n",
            "Training Epoch 8:  75%|███████▍  | 2766/3689 [04:57<01:39,  9.28batch/s, accuracy=0.983, loss=0.0563]\u001b[A\n",
            "Training Epoch 8:  75%|███████▍  | 2766/3689 [05:11<01:39,  9.28batch/s, accuracy=0.983, loss=0.0563]\u001b[A\n",
            "Training Epoch 8: 100%|█████████▉| 3688/3689 [06:37<00:00,  9.27batch/s, accuracy=0.983, loss=0.0563]\u001b[A\n",
            "Training Epoch 8: 100%|█████████▉| 3688/3689 [06:37<00:00,  9.27batch/s, accuracy=0.983, loss=0.0571]\n",
            "\n",
            "Validation Epoch 8:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 8:  50%|████▉     | 790/1581 [00:32<00:32, 24.41batch/s]\u001b[A\n",
            "Validation Epoch 8:  50%|████▉     | 790/1581 [00:32<00:32, 24.41batch/s, accuracy=0.949, loss=0.202]\u001b[A\n",
            "Validation Epoch 8:  50%|████▉     | 790/1581 [00:43<00:32, 24.41batch/s, accuracy=0.949, loss=0.202]\u001b[A\n",
            "Validation Epoch 8: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.80batch/s, accuracy=0.949, loss=0.202]\u001b[A\n",
            "Validation Epoch 8: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.73batch/s, accuracy=0.964, loss=0.144]\n",
            "\n",
            "Training Epoch 9:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 9:  25%|██▍       | 922/3689 [01:39<04:57,  9.29batch/s]\u001b[A\n",
            "Training Epoch 9:  25%|██▍       | 922/3689 [01:39<04:57,  9.29batch/s, accuracy=0.987, loss=0.045]\u001b[A\n",
            "Training Epoch 9:  25%|██▍       | 922/3689 [01:49<04:57,  9.29batch/s, accuracy=0.987, loss=0.045]\u001b[A\n",
            "Training Epoch 9:  50%|████▉     | 1844/3689 [03:19<03:19,  9.25batch/s, accuracy=0.987, loss=0.045]\u001b[A\n",
            "Training Epoch 9:  50%|████▉     | 1844/3689 [03:19<03:19,  9.25batch/s, accuracy=0.986, loss=0.0451]\u001b[A\n",
            "Training Epoch 9:  50%|████▉     | 1844/3689 [03:29<03:19,  9.25batch/s, accuracy=0.986, loss=0.0451]\u001b[A\n",
            "Training Epoch 9:  75%|███████▍  | 2766/3689 [04:58<01:39,  9.26batch/s, accuracy=0.986, loss=0.0451]\u001b[A\n",
            "Training Epoch 9:  75%|███████▍  | 2766/3689 [04:58<01:39,  9.26batch/s, accuracy=0.986, loss=0.0468]\u001b[A\n",
            "Training Epoch 9:  75%|███████▍  | 2766/3689 [05:09<01:39,  9.26batch/s, accuracy=0.986, loss=0.0468]\u001b[A\n",
            "Training Epoch 9: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.26batch/s, accuracy=0.986, loss=0.0468]\u001b[A\n",
            "Training Epoch 9: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.26batch/s, accuracy=0.986, loss=0.0456]\n",
            "\n",
            "Validation Epoch 9:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 9:  50%|████▉     | 790/1581 [00:32<00:32, 24.46batch/s]\u001b[A\n",
            "Validation Epoch 9:  50%|████▉     | 790/1581 [00:32<00:32, 24.46batch/s, accuracy=0.937, loss=0.234]\u001b[A\n",
            "Validation Epoch 9:  50%|████▉     | 790/1581 [00:44<00:32, 24.46batch/s, accuracy=0.937, loss=0.234]\u001b[A\n",
            "Validation Epoch 9: 100%|█████████▉| 1580/1581 [01:04<00:00, 24.69batch/s, accuracy=0.937, loss=0.234]\u001b[A\n",
            "Validation Epoch 9: 100%|█████████▉| 1580/1581 [01:04<00:00, 24.64batch/s, accuracy=0.957, loss=0.161]\n",
            "\n",
            "Training Epoch 10:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 10:  25%|██▍       | 922/3689 [01:39<04:58,  9.28batch/s]\u001b[A\n",
            "Training Epoch 10:  25%|██▍       | 922/3689 [01:39<04:58,  9.28batch/s, accuracy=0.987, loss=0.0395]\u001b[A\n",
            "Training Epoch 10:  25%|██▍       | 922/3689 [01:50<04:58,  9.28batch/s, accuracy=0.987, loss=0.0395]\u001b[A\n",
            "Training Epoch 10:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.987, loss=0.0395]\u001b[A\n",
            "Training Epoch 10:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.987, loss=0.0399]\u001b[A\n",
            "Training Epoch 10:  50%|████▉     | 1844/3689 [03:30<03:19,  9.24batch/s, accuracy=0.987, loss=0.0399]\u001b[A\n",
            "Training Epoch 10:  75%|███████▍  | 2766/3689 [04:58<01:39,  9.25batch/s, accuracy=0.987, loss=0.0399]\u001b[A\n",
            "Training Epoch 10:  75%|███████▍  | 2766/3689 [04:58<01:39,  9.25batch/s, accuracy=0.987, loss=0.0429]\u001b[A\n",
            "Training Epoch 10:  75%|███████▍  | 2766/3689 [05:10<01:39,  9.25batch/s, accuracy=0.987, loss=0.0429]\u001b[A\n",
            "Training Epoch 10: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.25batch/s, accuracy=0.987, loss=0.0429]\u001b[A\n",
            "Training Epoch 10: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.25batch/s, accuracy=0.987, loss=0.0434]\n",
            "\n",
            "Validation Epoch 10:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 10:  50%|████▉     | 790/1581 [00:32<00:32, 24.39batch/s]\u001b[A\n",
            "Validation Epoch 10:  50%|████▉     | 790/1581 [00:32<00:32, 24.39batch/s, accuracy=0.946, loss=0.24]\u001b[A\n",
            "Validation Epoch 10:  50%|████▉     | 790/1581 [00:48<00:32, 24.39batch/s, accuracy=0.946, loss=0.24]\u001b[A\n",
            "Validation Epoch 10: 100%|█████████▉| 1580/1581 [01:04<00:00, 24.46batch/s, accuracy=0.946, loss=0.24]\u001b[A\n",
            "Validation Epoch 10: 100%|█████████▉| 1580/1581 [01:04<00:00, 24.43batch/s, accuracy=0.962, loss=0.17]\n",
            "\n",
            "Training Epoch 11:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 11:  25%|██▍       | 922/3689 [01:39<04:58,  9.26batch/s]\u001b[A\n",
            "Training Epoch 11:  25%|██▍       | 922/3689 [01:39<04:58,  9.26batch/s, accuracy=0.99, loss=0.032]\u001b[A\n",
            "Training Epoch 11:  25%|██▍       | 922/3689 [01:53<04:58,  9.26batch/s, accuracy=0.99, loss=0.032]\u001b[A\n",
            "Training Epoch 11:  50%|████▉     | 1844/3689 [03:19<03:19,  9.25batch/s, accuracy=0.99, loss=0.032]\u001b[A\n",
            "Training Epoch 11:  50%|████▉     | 1844/3689 [03:19<03:19,  9.25batch/s, accuracy=0.989, loss=0.0354]\u001b[A\n",
            "Training Epoch 11:  50%|████▉     | 1844/3689 [03:33<03:19,  9.25batch/s, accuracy=0.989, loss=0.0354]\u001b[A\n",
            "Training Epoch 11:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.989, loss=0.0354]\u001b[A\n",
            "Training Epoch 11:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.988, loss=0.0401]\u001b[A\n",
            "Training Epoch 11:  75%|███████▍  | 2766/3689 [05:13<01:39,  9.24batch/s, accuracy=0.988, loss=0.0401]\u001b[A\n",
            "Training Epoch 11: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.26batch/s, accuracy=0.988, loss=0.0401]\u001b[A\n",
            "Training Epoch 11: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.26batch/s, accuracy=0.988, loss=0.0399]\n",
            "\n",
            "Validation Epoch 11:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 11:  50%|████▉     | 790/1581 [00:31<00:31, 25.14batch/s]\u001b[A\n",
            "Validation Epoch 11:  50%|████▉     | 790/1581 [00:31<00:31, 25.14batch/s, accuracy=0.949, loss=0.226]\u001b[A\n",
            "Validation Epoch 11:  50%|████▉     | 790/1581 [00:45<00:31, 25.14batch/s, accuracy=0.949, loss=0.226]\u001b[A\n",
            "Validation Epoch 11: 100%|█████████▉| 1580/1581 [01:02<00:00, 25.15batch/s, accuracy=0.949, loss=0.226]\u001b[A\n",
            "Validation Epoch 11: 100%|█████████▉| 1580/1581 [01:02<00:00, 25.13batch/s, accuracy=0.962, loss=0.165]\n",
            "\n",
            "Training Epoch 12:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 12:  25%|██▍       | 922/3689 [01:39<04:57,  9.29batch/s]\u001b[A\n",
            "Training Epoch 12:  25%|██▍       | 922/3689 [01:39<04:57,  9.29batch/s, accuracy=0.991, loss=0.031]\u001b[A\n",
            "Training Epoch 12:  25%|██▍       | 922/3689 [01:52<04:57,  9.29batch/s, accuracy=0.991, loss=0.031]\u001b[A\n",
            "Training Epoch 12:  50%|████▉     | 1844/3689 [03:18<03:18,  9.27batch/s, accuracy=0.991, loss=0.031]\u001b[A\n",
            "Training Epoch 12:  50%|████▉     | 1844/3689 [03:18<03:18,  9.27batch/s, accuracy=0.99, loss=0.0323]\u001b[A\n",
            "Training Epoch 12:  50%|████▉     | 1844/3689 [03:32<03:18,  9.27batch/s, accuracy=0.99, loss=0.0323]\u001b[A\n",
            "Training Epoch 12:  75%|███████▍  | 2766/3689 [04:58<01:39,  9.27batch/s, accuracy=0.99, loss=0.0323]\u001b[A\n",
            "Training Epoch 12:  75%|███████▍  | 2766/3689 [04:58<01:39,  9.27batch/s, accuracy=0.99, loss=0.0345]\u001b[A\n",
            "Training Epoch 12:  75%|███████▍  | 2766/3689 [05:12<01:39,  9.27batch/s, accuracy=0.99, loss=0.0345]\u001b[A\n",
            "Training Epoch 12: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.26batch/s, accuracy=0.99, loss=0.0345]\u001b[A\n",
            "Training Epoch 12: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.26batch/s, accuracy=0.989, loss=0.0365]\n",
            "\n",
            "Validation Epoch 12:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 12:  50%|████▉     | 790/1581 [00:32<00:32, 24.47batch/s]\u001b[A\n",
            "Validation Epoch 12:  50%|████▉     | 790/1581 [00:32<00:32, 24.47batch/s, accuracy=0.95, loss=0.213]\u001b[A\n",
            "Validation Epoch 12:  50%|████▉     | 790/1581 [00:44<00:32, 24.47batch/s, accuracy=0.95, loss=0.213]\u001b[A\n",
            "Validation Epoch 12: 100%|█████████▉| 1580/1581 [01:04<00:00, 24.46batch/s, accuracy=0.95, loss=0.213]\u001b[A\n",
            "Validation Epoch 12: 100%|█████████▉| 1580/1581 [01:04<00:00, 24.45batch/s, accuracy=0.965, loss=0.156]\n",
            "\n",
            "Training Epoch 13:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 13:  25%|██▍       | 922/3689 [01:40<05:00,  9.21batch/s]\u001b[A\n",
            "Training Epoch 13:  25%|██▍       | 922/3689 [01:40<05:00,  9.21batch/s, accuracy=0.99, loss=0.0281]\u001b[A\n",
            "Training Epoch 13:  25%|██▍       | 922/3689 [01:53<05:00,  9.21batch/s, accuracy=0.99, loss=0.0281]\u001b[A\n",
            "Training Epoch 13:  50%|████▉     | 1844/3689 [03:20<03:20,  9.21batch/s, accuracy=0.99, loss=0.0281]\u001b[A\n",
            "Training Epoch 13:  50%|████▉     | 1844/3689 [03:20<03:20,  9.21batch/s, accuracy=0.99, loss=0.0311]\u001b[A\n",
            "Training Epoch 13:  50%|████▉     | 1844/3689 [03:33<03:20,  9.21batch/s, accuracy=0.99, loss=0.0311]\u001b[A\n",
            "Training Epoch 13:  75%|███████▍  | 2766/3689 [05:00<01:40,  9.21batch/s, accuracy=0.99, loss=0.0311]\u001b[A\n",
            "Training Epoch 13:  75%|███████▍  | 2766/3689 [05:00<01:40,  9.21batch/s, accuracy=0.99, loss=0.0309]\u001b[A\n",
            "Training Epoch 13:  75%|███████▍  | 2766/3689 [05:13<01:40,  9.21batch/s, accuracy=0.99, loss=0.0309]\u001b[A\n",
            "Training Epoch 13: 100%|█████████▉| 3688/3689 [06:40<00:00,  9.21batch/s, accuracy=0.99, loss=0.0309]\u001b[A\n",
            "Training Epoch 13: 100%|█████████▉| 3688/3689 [06:40<00:00,  9.21batch/s, accuracy=0.991, loss=0.0313]\n",
            "\n",
            "Validation Epoch 13:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 13:  50%|████▉     | 790/1581 [00:32<00:32, 24.39batch/s]\u001b[A\n",
            "Validation Epoch 13:  50%|████▉     | 790/1581 [00:32<00:32, 24.39batch/s, accuracy=0.949, loss=0.239]\u001b[A\n",
            "Validation Epoch 13:  50%|████▉     | 790/1581 [00:42<00:32, 24.39batch/s, accuracy=0.949, loss=0.239]\u001b[A\n",
            "Validation Epoch 13: 100%|█████████▉| 1580/1581 [01:04<00:00, 24.46batch/s, accuracy=0.949, loss=0.239]\u001b[A\n",
            "Validation Epoch 13: 100%|█████████▉| 1580/1581 [01:04<00:00, 24.43batch/s, accuracy=0.964, loss=0.166]\n",
            "\n",
            "Training Epoch 14:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 14:  25%|██▍       | 922/3689 [01:40<05:00,  9.22batch/s]\u001b[A\n",
            "Training Epoch 14:  25%|██▍       | 922/3689 [01:40<05:00,  9.22batch/s, accuracy=0.991, loss=0.0318]\u001b[A\n",
            "Training Epoch 14:  25%|██▍       | 922/3689 [01:54<05:00,  9.22batch/s, accuracy=0.991, loss=0.0318]\u001b[A\n",
            "Training Epoch 14:  50%|████▉     | 1844/3689 [03:20<03:20,  9.22batch/s, accuracy=0.991, loss=0.0318]\u001b[A\n",
            "Training Epoch 14:  50%|████▉     | 1844/3689 [03:20<03:20,  9.22batch/s, accuracy=0.991, loss=0.0279]\u001b[A\n",
            "Training Epoch 14:  50%|████▉     | 1844/3689 [03:34<03:20,  9.22batch/s, accuracy=0.991, loss=0.0279]\u001b[A\n",
            "Training Epoch 14:  75%|███████▍  | 2766/3689 [05:00<01:40,  9.22batch/s, accuracy=0.991, loss=0.0279]\u001b[A\n",
            "Training Epoch 14:  75%|███████▍  | 2766/3689 [05:00<01:40,  9.22batch/s, accuracy=0.991, loss=0.0294]\u001b[A\n",
            "Training Epoch 14:  75%|███████▍  | 2766/3689 [05:14<01:40,  9.22batch/s, accuracy=0.991, loss=0.0294]\u001b[A\n",
            "Training Epoch 14: 100%|█████████▉| 3688/3689 [06:40<00:00,  9.22batch/s, accuracy=0.991, loss=0.0294]\u001b[A\n",
            "Training Epoch 14: 100%|█████████▉| 3688/3689 [06:40<00:00,  9.22batch/s, accuracy=0.991, loss=0.0307]\n",
            "\n",
            "Validation Epoch 14:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 14:  50%|████▉     | 790/1581 [00:32<00:32, 24.40batch/s]\u001b[A\n",
            "Validation Epoch 14:  50%|████▉     | 790/1581 [00:32<00:32, 24.40batch/s, accuracy=0.948, loss=0.25]\u001b[A\n",
            "Validation Epoch 14:  50%|████▉     | 790/1581 [00:43<00:32, 24.40batch/s, accuracy=0.948, loss=0.25]\u001b[A\n",
            "Validation Epoch 14: 100%|█████████▉| 1580/1581 [01:04<00:00, 24.52batch/s, accuracy=0.948, loss=0.25]\u001b[A\n",
            "Validation Epoch 14: 100%|█████████▉| 1580/1581 [01:04<00:00, 24.49batch/s, accuracy=0.964, loss=0.179]\n",
            "\n",
            "Training Epoch 15:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 15:  25%|██▍       | 922/3689 [01:39<05:00,  9.22batch/s]\u001b[A\n",
            "Training Epoch 15:  25%|██▍       | 922/3689 [01:39<05:00,  9.22batch/s, accuracy=0.99, loss=0.0281]\u001b[A\n",
            "Training Epoch 15:  25%|██▍       | 922/3689 [01:53<05:00,  9.22batch/s, accuracy=0.99, loss=0.0281]\u001b[A\n",
            "Training Epoch 15:  50%|████▉     | 1844/3689 [03:20<03:20,  9.22batch/s, accuracy=0.99, loss=0.0281]\u001b[A\n",
            "Training Epoch 15:  50%|████▉     | 1844/3689 [03:20<03:20,  9.22batch/s, accuracy=0.991, loss=0.0259]\u001b[A\n",
            "Training Epoch 15:  50%|████▉     | 1844/3689 [03:33<03:20,  9.22batch/s, accuracy=0.991, loss=0.0259]\u001b[A\n",
            "Training Epoch 15:  75%|███████▍  | 2766/3689 [04:59<01:40,  9.22batch/s, accuracy=0.991, loss=0.0259]\u001b[A\n",
            "Training Epoch 15:  75%|███████▍  | 2766/3689 [04:59<01:40,  9.22batch/s, accuracy=0.991, loss=0.0262]\u001b[A\n",
            "Training Epoch 15:  75%|███████▍  | 2766/3689 [05:13<01:40,  9.22batch/s, accuracy=0.991, loss=0.0262]\u001b[A\n",
            "Training Epoch 15: 100%|█████████▉| 3688/3689 [06:39<00:00,  9.23batch/s, accuracy=0.991, loss=0.0262]\u001b[A\n",
            "Training Epoch 15: 100%|█████████▉| 3688/3689 [06:39<00:00,  9.22batch/s, accuracy=0.992, loss=0.0267]\n",
            "\n",
            "Validation Epoch 15:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 15:  50%|████▉     | 790/1581 [00:31<00:31, 24.75batch/s]\u001b[A\n",
            "Validation Epoch 15:  50%|████▉     | 790/1581 [00:31<00:31, 24.75batch/s, accuracy=0.945, loss=0.253]\u001b[A\n",
            "Validation Epoch 15:  50%|████▉     | 790/1581 [00:43<00:31, 24.75batch/s, accuracy=0.945, loss=0.253]\u001b[A\n",
            "Validation Epoch 15: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.87batch/s, accuracy=0.945, loss=0.253]\u001b[A\n",
            "Validation Epoch 15: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.83batch/s, accuracy=0.961, loss=0.183]\n",
            "\n",
            "Training Epoch 16:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 16:  25%|██▍       | 922/3689 [01:39<04:59,  9.24batch/s]\u001b[A\n",
            "Training Epoch 16:  25%|██▍       | 922/3689 [01:39<04:59,  9.24batch/s, accuracy=0.992, loss=0.0252]\u001b[A\n",
            "Training Epoch 16:  25%|██▍       | 922/3689 [01:55<04:59,  9.24batch/s, accuracy=0.992, loss=0.0252]\u001b[A\n",
            "Training Epoch 16:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.992, loss=0.0252]\u001b[A\n",
            "Training Epoch 16:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.991, loss=0.0281]\u001b[A\n",
            "Training Epoch 16:  50%|████▉     | 1844/3689 [03:29<03:19,  9.24batch/s, accuracy=0.991, loss=0.0281]\u001b[A\n",
            "Training Epoch 16:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.991, loss=0.0281]\u001b[A\n",
            "Training Epoch 16:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.991, loss=0.0306]\u001b[A\n",
            "Training Epoch 16:  75%|███████▍  | 2766/3689 [05:09<01:39,  9.24batch/s, accuracy=0.991, loss=0.0306]\u001b[A\n",
            "Training Epoch 16: 100%|█████████▉| 3688/3689 [06:39<00:00,  9.24batch/s, accuracy=0.991, loss=0.0306]\u001b[A\n",
            "Training Epoch 16: 100%|█████████▉| 3688/3689 [06:39<00:00,  9.24batch/s, accuracy=0.992, loss=0.0276]\n",
            "\n",
            "Validation Epoch 16:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 16:  50%|████▉     | 790/1581 [00:31<00:31, 24.78batch/s]\u001b[A\n",
            "Validation Epoch 16:  50%|████▉     | 790/1581 [00:31<00:31, 24.78batch/s, accuracy=0.952, loss=0.277]\u001b[A\n",
            "Validation Epoch 16:  50%|████▉     | 790/1581 [00:46<00:31, 24.78batch/s, accuracy=0.952, loss=0.277]\u001b[A\n",
            "Validation Epoch 16: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.83batch/s, accuracy=0.952, loss=0.277]\u001b[A\n",
            "Validation Epoch 16: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.81batch/s, accuracy=0.965, loss=0.198]\n",
            "\n",
            "Training Epoch 17:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 17:  25%|██▍       | 922/3689 [01:39<04:59,  9.24batch/s]\u001b[A\n",
            "Training Epoch 17:  25%|██▍       | 922/3689 [01:39<04:59,  9.24batch/s, accuracy=0.993, loss=0.0256]\u001b[A\n",
            "Training Epoch 17:  25%|██▍       | 922/3689 [01:52<04:59,  9.24batch/s, accuracy=0.993, loss=0.0256]\u001b[A\n",
            "Training Epoch 17:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.993, loss=0.0256]\u001b[A\n",
            "Training Epoch 17:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.993, loss=0.0236]\u001b[A\n",
            "Training Epoch 17:  50%|████▉     | 1844/3689 [03:32<03:19,  9.24batch/s, accuracy=0.993, loss=0.0236]\u001b[A\n",
            "Training Epoch 17:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.993, loss=0.0236]\u001b[A\n",
            "Training Epoch 17:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.993, loss=0.0232]\u001b[A\n",
            "Training Epoch 17:  75%|███████▍  | 2766/3689 [05:12<01:39,  9.24batch/s, accuracy=0.993, loss=0.0232]\u001b[A\n",
            "Training Epoch 17: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.25batch/s, accuracy=0.993, loss=0.0232]\u001b[A\n",
            "Training Epoch 17: 100%|█████████▉| 3688/3689 [06:38<00:00,  9.24batch/s, accuracy=0.992, loss=0.0263]\n",
            "\n",
            "Validation Epoch 17:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 17:  50%|████▉     | 790/1581 [00:31<00:32, 24.71batch/s]\u001b[A\n",
            "Validation Epoch 17:  50%|████▉     | 790/1581 [00:31<00:32, 24.71batch/s, accuracy=0.943, loss=0.242]\u001b[A\n",
            "Validation Epoch 17:  50%|████▉     | 790/1581 [00:43<00:32, 24.71batch/s, accuracy=0.943, loss=0.242]\u001b[A\n",
            "Validation Epoch 17: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.82batch/s, accuracy=0.943, loss=0.242]\u001b[A\n",
            "Validation Epoch 17: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.79batch/s, accuracy=0.959, loss=0.175]\n",
            "\n",
            "Training Epoch 18:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 18:  25%|██▍       | 922/3689 [01:39<04:59,  9.23batch/s]\u001b[A\n",
            "Training Epoch 18:  25%|██▍       | 922/3689 [01:39<04:59,  9.23batch/s, accuracy=0.994, loss=0.0177]\u001b[A\n",
            "Training Epoch 18:  25%|██▍       | 922/3689 [01:49<04:59,  9.23batch/s, accuracy=0.994, loss=0.0177]\u001b[A\n",
            "Training Epoch 18:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.994, loss=0.0177]\u001b[A\n",
            "Training Epoch 18:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.993, loss=0.0234]\u001b[A\n",
            "Training Epoch 18:  50%|████▉     | 1844/3689 [03:29<03:19,  9.24batch/s, accuracy=0.993, loss=0.0234]\u001b[A\n",
            "Training Epoch 18:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.993, loss=0.0234]\u001b[A\n",
            "Training Epoch 18:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.24batch/s, accuracy=0.993, loss=0.0236]\u001b[A\n",
            "Training Epoch 18:  75%|███████▍  | 2766/3689 [05:10<01:39,  9.24batch/s, accuracy=0.993, loss=0.0236]\u001b[A\n",
            "Training Epoch 18: 100%|█████████▉| 3688/3689 [06:39<00:00,  9.24batch/s, accuracy=0.993, loss=0.0236]\u001b[A\n",
            "Training Epoch 18: 100%|█████████▉| 3688/3689 [06:39<00:00,  9.24batch/s, accuracy=0.992, loss=0.0253]\n",
            "\n",
            "Validation Epoch 18:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 18:  50%|████▉     | 790/1581 [00:31<00:31, 24.73batch/s]\u001b[A\n",
            "Validation Epoch 18:  50%|████▉     | 790/1581 [00:31<00:31, 24.73batch/s, accuracy=0.946, loss=0.239]\u001b[A\n",
            "Validation Epoch 18:  50%|████▉     | 790/1581 [00:44<00:31, 24.73batch/s, accuracy=0.946, loss=0.239]\u001b[A\n",
            "Validation Epoch 18: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.79batch/s, accuracy=0.946, loss=0.239]\u001b[A\n",
            "Validation Epoch 18: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.76batch/s, accuracy=0.961, loss=0.175]\n",
            "\n",
            "Training Epoch 19:   0%|          | 0/3689 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Training Epoch 19:  25%|██▍       | 922/3689 [01:39<04:59,  9.24batch/s]\u001b[A\n",
            "Training Epoch 19:  25%|██▍       | 922/3689 [01:39<04:59,  9.24batch/s, accuracy=0.995, loss=0.0178]\u001b[A\n",
            "Training Epoch 19:  25%|██▍       | 922/3689 [01:50<04:59,  9.24batch/s, accuracy=0.995, loss=0.0178]\u001b[A\n",
            "Training Epoch 19:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.995, loss=0.0178]\u001b[A\n",
            "Training Epoch 19:  50%|████▉     | 1844/3689 [03:19<03:19,  9.24batch/s, accuracy=0.994, loss=0.0204]\u001b[A\n",
            "Training Epoch 19:  50%|████▉     | 1844/3689 [03:30<03:19,  9.24batch/s, accuracy=0.994, loss=0.0204]\u001b[A\n",
            "Training Epoch 19:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.23batch/s, accuracy=0.994, loss=0.0204]\u001b[A\n",
            "Training Epoch 19:  75%|███████▍  | 2766/3689 [04:59<01:39,  9.23batch/s, accuracy=0.993, loss=0.0226]\u001b[A\n",
            "Training Epoch 19:  75%|███████▍  | 2766/3689 [05:10<01:39,  9.23batch/s, accuracy=0.993, loss=0.0226]\u001b[A\n",
            "Training Epoch 19: 100%|█████████▉| 3688/3689 [06:39<00:00,  9.23batch/s, accuracy=0.993, loss=0.0226]\u001b[A\n",
            "Training Epoch 19: 100%|█████████▉| 3688/3689 [06:39<00:00,  9.23batch/s, accuracy=0.993, loss=0.025]\n",
            "\n",
            "Validation Epoch 19:   0%|          | 0/1581 [00:00<?, ?batch/s]\u001b[A<ipython-input-51-098a97ba1349>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tokens_padded = torch.stack([torch.cat([torch.tensor(token[:max_length], dtype=torch.long), torch.tensor([tokenizer.pad_token_id] * (max_length - len(token)), dtype=torch.long)]) if len(token) < max_length else torch.tensor(token[:max_length], dtype=torch.long) for token in tokens])\n",
            "\n",
            "Validation Epoch 19:  50%|████▉     | 790/1581 [00:32<00:32, 24.66batch/s]\u001b[A\n",
            "Validation Epoch 19:  50%|████▉     | 790/1581 [00:32<00:32, 24.66batch/s, accuracy=0.94, loss=0.291]\u001b[A\n",
            "Validation Epoch 19:  50%|████▉     | 790/1581 [00:47<00:32, 24.66batch/s, accuracy=0.94, loss=0.291]\u001b[A\n",
            "Validation Epoch 19: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.80batch/s, accuracy=0.94, loss=0.291]\u001b[A\n",
            "Validation Epoch 19: 100%|█████████▉| 1580/1581 [01:03<00:00, 24.76batch/s, accuracy=0.957, loss=0.211]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 지표 출력 및 저장\n",
        "metrics_3 = {\n",
        "    'model_name': model_name,\n",
        "    'train_accuracy': train_accuracies,\n",
        "    'val_accuracy': val_accuracies,\n",
        "    'train_loss': train_losses,\n",
        "    'val_loss': val_losses,\n",
        "    'precision': precisions,\n",
        "    'recall': recalls,\n",
        "    'f1_score': f1_scores\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame([metrics_3])\n",
        "metrics_df.to_csv('KcBert_metrics.csv', index=False)\n",
        "print(\"KcBERT metrics saved.\")\n",
        "files.download('KcBert_metrics.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hmb2579Bfgt1",
        "outputId": "48e8d1d3-1eb3-41a5-9a02-f961b7e61003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KcBERT metrics saved.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f3754c14-3419-4de5-b03b-b1ad09e65505\", \"KcBert_metrics.csv\", 2943)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}