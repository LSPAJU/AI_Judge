{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExcdCGTJ8Icy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "t8zLgQPQ8P7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/판례_본문.xlsx')"
      ],
      "metadata": {
        "id": "7vgFZW3D8ihm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "aKNy-Pk38mMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = pd.read_excel('/content/drive/MyDrive/df_semi_final.xlsx')"
      ],
      "metadata": {
        "id": "uxVmuoom8mdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2_num = df_2[['사건번호']]\n",
        "\n",
        "print(df_2_num.head())"
      ],
      "metadata": {
        "id": "jVSXuR32BPhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_1에서 사건번호가 df_2_num의 사건번호와 일치하는 데이터를 추출\n",
        "df_3 = df_1[df_1['사건번호'].isin(df_2_num['사건번호'])]\n",
        "\n",
        "# 결과 확인\n",
        "print(df_3.head())"
      ],
      "metadata": {
        "id": "SQVK3ItTBRGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2_selected = df_2[['사건번호', '판결유형']]"
      ],
      "metadata": {
        "id": "A0WsUWBNCC47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_3에 df_2_selected와 사건번호 기준으로 병합하여 판결유형 업데이트\n",
        "df_3_updated = df_3.merge(df_2_selected, on='사건번호', how='left', suffixes=('', '_new'))\n",
        "\n",
        "# 판결내용이 있는 경우 df_2의 판결내용으로 대체\n",
        "df_3_updated['판결유형'] = df_3_updated['판결유형_new'].fillna(df_3_updated['판결유형'])\n",
        "\n",
        "# 필요 없는 판결내용_new 열 삭제\n",
        "df_3_updated.drop(columns=['판결유형_new'], inplace=True)\n",
        "\n",
        "# 결과 확인\n",
        "print(df_3_updated.head())"
      ],
      "metadata": {
        "id": "0N_HLpOcCE0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 열만 남기기\n",
        "df_4 = df_updated[['사건명', '사건번호', '사건종류명', '판결유형', '판시사항', '판결요지', '판례내용']]\n",
        "\n",
        "# 결과 확인\n",
        "print(df_4.head())\n",
        "print(df_4.columns)"
      ],
      "metadata": {
        "id": "Etw_Z0BNCPQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특수 문자 및 불필요한 공백 제거 함수\n",
        "def clean_text(text):\n",
        "    # 텍스트가 비어있는 경우 빈 문자열 반환\n",
        "    if pd.isna(text):\n",
        "        return ''\n",
        "    # 특수 문자 제거 (필요시 조정 가능)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # 다중 공백을 단일 공백으로 대체\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# 판시사항, 판결요지, 판례내용 열에 대해 전처리 적용\n",
        "df_4['판시사항'] = df_4['판시사항'].apply(clean_text)\n",
        "df_4['판결요지'] = df_4['판결요지'].apply(clean_text)\n",
        "df_4['판례내용'] = df_4['판례내용'].apply(clean_text)\n",
        "\n",
        "# 중복된 데이터 제거 (선택사항)\n",
        "df_4.drop_duplicates(subset=['사건명', '사건종류명', '판결유형', '판시사항', '판결요지', '판례내용'], inplace=True)\n",
        "\n",
        "# 전처리 후 결과 확인\n",
        "print(df_4.head())"
      ],
      "metadata": {
        "id": "1PaBfNYWCZM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_4.to_excel('df_final_real.xlsx', index=False)\n",
        "files.download('df_final_real.xlsx')"
      ],
      "metadata": {
        "id": "X5JtZ8gHnrZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **토큰화 작업**"
      ],
      "metadata": {
        "id": "RG3MjxH5DPNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU가 사용 가능한지 확인하고 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# BERT 토크나이저 및 모델 불러오기\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=13)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "Hml5pe82DTVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 매핑을 사건 종류에 따라 다르게 적용하는 함수 정의\n",
        "label_map = {\n",
        "    '민사_승소': 0, '민사_패소': 1, '민사_기각': 2,\n",
        "    '형사_기각': 3, '징역': 4, '벌금': 5, '무혐의': 6,\n",
        "    '가사_승소': 7, '가사_패소': 8, '가사_기각': 9,\n",
        "    '세무_승소': 10, '세무_패소': 11, '세무_기각': 12\n",
        "}"
      ],
      "metadata": {
        "id": "5CxnhqRUDZAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_4 = df_4[df_4['판결유형'].isin(label_map.keys())]"
      ],
      "metadata": {
        "id": "UFMT8A6ZDeSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 데이터 전처리 및 토큰화 함수 정의 (tqdm 버전)\n",
        "def preprocess_and_tokenize(data, column_name):\n",
        "    tokenized_data = []\n",
        "    for idx, row in tqdm(data.iterrows(), total=len(data), desc=\"Tokenizing\"):\n",
        "        text = str(row[column_name])\n",
        "        # 전처리: 불필요한 공백 제거\n",
        "        text = \" \".join(text.split())\n",
        "        # 토큰화\n",
        "        tokens = tokenizer.encode(text, add_special_tokens=True, max_length=512, truncation=True)\n",
        "        tokenized_data.append(tokens)\n",
        "    return tokenized_data"
      ],
      "metadata": {
        "id": "vGtJvOPrDl9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 판례내용 토큰화\n",
        "df_4['판례내용_tokens'] = preprocess_and_tokenize(df_4, '판례내용')"
      ],
      "metadata": {
        "id": "iAvIl1_kDnek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_5 = df_4"
      ],
      "metadata": {
        "id": "O_qymrTWEMcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **임베딩 작업**"
      ],
      "metadata": {
        "id": "5KyhcqVpD6hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT 모델과 토크나이저 로드\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name).to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "ubOdD9IuD8PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 임베딩 생성 함수 정의\n",
        "def generate_embedding_from_tokens(tokens_list):\n",
        "    tokens_tensor = torch.tensor([tokens_list]).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids=tokens_tensor, attention_mask=(tokens_tensor > 0).long())\n",
        "    embedding = output.last_hidden_state[:, 0, :].cpu().numpy().flatten()\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "A-rbEM3uEBoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 임베딩 생성 및 데이터프레임에 추가\n",
        "embeddings = []\n",
        "for tokens in df['판례내용_tokens']:\n",
        "    if isinstance(tokens, str):\n",
        "        tokens = eval(tokens)\n",
        "    embeddings.append(generate_embedding_from_tokens(tokens))\n",
        "\n",
        "# df에 임베딩 열 추가\n",
        "df_5['임베딩'] = embeddings"
      ],
      "metadata": {
        "id": "0likgf9MEEQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 쉼표를 추가하는 함수 정의\n",
        "def add_commas_to_numbers_in_column(value):\n",
        "    if isinstance(value, str):\n",
        "        # 숫자와 숫자 사이의 공백을 쉼표로 변환\n",
        "        return re.sub(r'(?<=[\\d\\.\\-eE])\\s+(?=[\\d\\.\\-eE])', ', ', value)\n",
        "    return value\n",
        "\n",
        "# '임베딩' 열에 쉼표 추가\n",
        "if '임베딩' in df.columns:\n",
        "    df_5['임베딩'] = df_5['임베딩'].apply(add_commas_to_numbers_in_column)\n",
        "\n",
        "output_file_path = 'df_real_token_with_embeddings_with_commas.xlsx'\n",
        "df_5.to_excel(output_file_path, index=False)"
      ],
      "metadata": {
        "id": "m3G9NSo-EIC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('df_real_token_with_embeddings_with_commas.xlsx')"
      ],
      "metadata": {
        "id": "bZzQ8GA8nIDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}